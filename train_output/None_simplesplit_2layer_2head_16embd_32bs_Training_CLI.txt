python main.py --task train
GPU is enabled.
The file './tokenizer/simple_vocab.json' exists. Loading tokenizer.
{'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, 'I_TURN_RIGHT': 4, 'I_JUMP': 5, 'I_WALK': 6, 'I_TURN_LEFT': 7, 'I_RUN': 8, 'I_LOOK': 9, 'jump': 10, 'opposite': 11, 'right': 12, 'twice': 13, 'and': 14, 'turn': 15, 'thrice': 16, 'run': 17, 'left': 18, 'after': 19, 'walk': 20, 'around': 21, 'look': 22}
train dataset size: 15055
val dataset size: 1673
loading model
total params: 8128
epoch 1 iter 470: train loss 1.36076. lr 3.9979e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 54.70it/s]
Traceback (most recent call last):
  File "main.py", line 74, in <module>
    train(args)
  File "C:\Users\hussein\Desktop\DL-GPT-for-scan\train.py", line 45, in train
    trainer.train()
  File "C:\Users\hussein\Desktop\DL-GPT-for-scan\trainer.py", line 153, in train
    test_loss = run_epoch('test')
  File "C:\Users\hussein\Desktop\DL-GPT-for-scan\trainer.py", line 93, in run_epoch
    pbar = tqdm(enumerate(loader), total=len(loader), desc=f"epoch {epoch + 1} iter {0}: train loss {0:.5f}. lr {0:.4e}") if is_train else enumerate(loader)
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\utils\data\dataloader.py", line 438, in __iter__
    return self._get_iterator()
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\utils\data\dataloader.py", line 386, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\utils\data\dataloader.py", line 1084, in __init__
    self._reset(loader, first_iter=True)
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\utils\data\dataloader.py", line 1117, in _reset
    self._try_put_index()
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\utils\data\dataloader.py", line 1351, in _try_put_index
    index = self._next_index()
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\utils\data\dataloader.py", line 620, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\utils\data\sampler.py", line 285, in __iter__
    if idx_in_batch == self.batch_size:
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "C:\Users\hussein\anaconda3\envs\csce\lib\multiprocessing\util.py", line 357, in _exit_function
    p.join()
  File "C:\Users\hussein\anaconda3\envs\csce\lib\multiprocessing\process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "C:\Users\hussein\anaconda3\envs\csce\lib\multiprocessing\popen_spawn_win32.py", line 108, in wait
    res = _winapi.WaitForSingleObject(int(self._handle), msecs)
KeyboardInterrupt
^C
(csce) C:\Users\hussein\Desktop\DL-GPT-for-scan>python main.py --task train
GPU is enabled.
The file './tokenizer/simple_vocab.json' exists. Loading tokenizer.
{'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, 'I_TURN_RIGHT': 4, 'I_JUMP': 5, 'I_WALK': 6, 'I_TURN_LEFT': 7, 'I_RUN': 8, 'I_LOOK': 9, 'jump': 10, 'opposite': 11, 'right': 12, 'twice': 13, 'and': 14, 'turn': 15, 'thrice': 16, 'run': 17, 'left': 18, 'after': 19, 'walk': 20, 'around': 21, 'look': 22}
train dataset size: 15055
val dataset size: 1673
loading model
total params: 8128
epoch 1 iter 470: train loss 1.36076. lr 3.9979e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 65.87it/s]
test loss: %f 1.3315630858799197
epoch_valid_loss: 1.3315630858799197, epoch_train_loss: 2.010460895084778, epoch: 1
Saving at epoch 1: ./cond_gpt/weights/None_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 1.3563321828842163 train_step: 500, learning_rate: 0.00039975616570522306                                                  | 28/471 [00:00<00:06, 66.66it/s]
epoch 2 iter 470: train loss 0.84086. lr 3.9905e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 68.82it/s] 
test loss: %f 0.8532606948096797
epoch_valid_loss: 0.8532606948096797, epoch_train_loss: 1.0851095147952912, epoch: 2
Saving at epoch 2: ./cond_gpt/weights/None_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.8487787246704102 train_step: 1000, learning_rate: 0.00039892135085140966                                                 | 51/471 [00:00<00:05, 72.17it/s]
epoch 3 iter 470: train loss 0.77631. lr 3.9779e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 70.73it/s] 
test loss: %f 0.6996285566743815
epoch_valid_loss: 0.6996285566743815, epoch_train_loss: 0.8357678907438955, epoch: 3
Saving at epoch 3: ./cond_gpt/weights/None_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.7291160821914673 train_step: 1500, learning_rate: 0.0003974953988637378                                                  | 83/471 [00:01<00:05, 69.67it/s]
epoch 4 iter 470: train loss 0.73402. lr 3.9601e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 71.77it/s] 
test loss: %f 0.6488848249867277
epoch_valid_loss: 0.6488848249867277, epoch_train_loss: 0.7547357972007395, epoch: 4
Saving at epoch 4: ./cond_gpt/weights/None_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.6697924733161926 train_step: 2000, learning_rate: 0.00039548254726204846                                                | 115/471 [00:01<00:04, 80.82it/s]
epoch 5 iter 470: train loss 0.72007. lr 3.9371e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 70.10it/s] 
test loss: %f 0.6011196616685616
epoch_valid_loss: 0.6011196616685616, epoch_train_loss: 0.7148372858699467, epoch: 5
Saving at epoch 5: ./cond_gpt/weights/None_simplesplit_2layer_2head_16embd_32bs.pt
step_train_loss: 0.6516755819320679 train_step: 2500, learning_rate: 0.00039288877766330537                                                | 138/471 [00:01<00:04, 73.58it/s]
epoch 6 iter 215: train loss 0.62486. lr 3.9248e-04:  46%|█████████████████████████████████████▏                                           | 216/471 [00:02<00:03, 75.74it/s] 
Traceback (most recent call last):
  File "main.py", line 74, in <module>
    train(args)
  File "C:\Users\hussein\Desktop\DL-GPT-for-scan\train.py", line 45, in train
    trainer.train()
  File "C:\Users\hussein\Desktop\DL-GPT-for-scan\trainer.py", line 151, in train
    train_loss = run_epoch('train')
  File "C:\Users\hussein\Desktop\DL-GPT-for-scan\trainer.py", line 104, in run_epoch
    logits, loss, _ = model(input_ids, targets=targets, condition_split_id=condition_split_id)
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\nn\parallel\data_parallel.py", line 183, in forward
    return self.module(*inputs[0], **module_kwargs[0])
  File "C:\Users\hussein\anaconda3\envs\csce\lib\site-packages\torch\autograd\profiler.py", line 636, in __exit__
    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any):
KeyboardInterrupt
^C
(csce) C:\Users\hussein\Desktop\DL-GPT-for-scan>python main.py --task train
GPU is enabled.
The file './tokenizer/simple_vocab.json' exists. Loading tokenizer.
{'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, 'I_TURN_RIGHT': 4, 'I_JUMP': 5, 'I_WALK': 6, 'I_TURN_LEFT': 7, 'I_RUN': 8, 'I_LOOK': 9, 'jump': 10, 'opposite': 11, 'right': 12, 'twice': 13, 'and': 14, 'turn': 15, 'thrice': 16, 'run': 17, 'left': 18, 'after': 19, 'walk': 20, 'around': 21, 'look': 22}
train dataset size: 15055
val dataset size: 1673
loading model
total params: 8128
epoch 1 iter 470: train loss 1.36076. lr 3.9979e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 71.50it/s]
test loss: %f 1.3315630858799197
step_train_loss: 1.3563321828842163 train_step: 500, learning_rate: 0.00039975616570522306                                                  | 29/471 [00:00<00:06, 70.57it/s]
epoch 2 iter 470: train loss 0.84086. lr 3.9905e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 71.72it/s] 
test loss: %f 0.8532606948096797
step_train_loss: 0.8487787246704102 train_step: 1000, learning_rate: 0.00039892135085140966                                                 | 53/471 [00:00<00:05, 76.76it/s]
epoch 3 iter 470: train loss 0.77631. lr 3.9779e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 70.85it/s] 
test loss: %f 0.6996285566743815
step_train_loss: 0.7291160821914673 train_step: 1500, learning_rate: 0.0003974953988637378                                                  | 85/471 [00:01<00:05, 73.45it/s]
epoch 4 iter 470: train loss 0.73402. lr 3.9601e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 69.46it/s] 
test loss: %f 0.6488848249867277
step_train_loss: 0.6697924733161926 train_step: 2000, learning_rate: 0.00039548254726204846                                                | 112/471 [00:01<00:04, 76.66it/s]
epoch 5 iter 470: train loss 0.72007. lr 3.9371e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 74.11it/s] 
test loss: %f 0.6011196616685616
step_train_loss: 0.6516755819320679 train_step: 2500, learning_rate: 0.00039288877766330537                                                | 144/471 [00:01<00:04, 77.88it/s]
epoch 6 iter 470: train loss 0.73957. lr 3.9090e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 71.91it/s] 
test loss: %f 0.5845241332953831
step_train_loss: 0.7590876221656799 train_step: 3000, learning_rate: 0.0003897217980059471                                                 | 170/471 [00:02<00:03, 78.47it/s]
epoch 7 iter 470: train loss 0.56798. lr 3.8758e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 68.09it/s] 
test loss: %f 0.5611452398435125
step_train_loss: 0.6735332608222961 train_step: 3500, learning_rate: 0.0003859910196441076██▉                                              | 203/471 [00:02<00:03, 70.03it/s]
epoch 8 iter 470: train loss 0.70311. lr 3.8377e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 67.13it/s] 
test loss: %f 0.5410441036494273
step_train_loss: 0.7164620757102966 train_step: 4000, learning_rate: 0.00038170752937977375██████▏                                         | 228/471 [00:03<00:03, 76.91it/s]
epoch 9 iter 470: train loss 0.57828. lr 3.7948e-04: 100%|█████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 72.11it/s] 
test loss: %f 0.5337894901914416
step_train_loss: 0.6456313729286194 train_step: 4500, learning_rate: 0.00037688405651599384██████████▉                                     | 253/471 [00:03<00:02, 84.94it/s]
epoch 10 iter 470: train loss 0.66703. lr 3.7471e-04: 100%|████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 78.29it/s] 
test loss: %f 0.5337894901914416
step_train_loss: 0.6456313729286194 train_step: 4500, learning_rate: 0.00037688405651599384██████████▉                                     | 253/471 [00:03<00:02, 84.94it/s]
epoch 10 iter 470: train loss 0.66703. lr 3.7471e-04: 100%|████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 78.29it/s]
test loss: %f 0.5086552399509358
step_train_loss: 0.625034749507904 train_step: 5000, learning_rate: 0.00037153493502904423██████████████████▎                              | 290/471 [00:03<00:01, 92.03it/s]
epoch 11 iter 470: train loss 0.78630. lr 3.6949e-04: 100%|████████████████████████████████████████████████████████████████████████████████| 471/471 [00:05<00:00, 84.14it/s]
test loss: %f 0.4891234450745133
step_train_loss: 0.692205011844635 train_step: 5500, learning_rate: 0.0003656760609719675███████████████████████▌                          | 315/471 [00:03<00:01, 92.86it/s]
epoch 12 iter 470: train loss 0.67885. lr 3.6381e-04: 100%|████████████████████████████████████████████████████████████████████████████████| 471/471 [00:05<00:00, 84.48it/s]
test loss: %f 0.495868980884552
step_train_loss: 0.7773244380950928 train_step: 6000, learning_rate: 0.0003593248452360679██████████████████████████▌                      | 339/471 [00:03<00:01, 91.08it/s]
epoch 13 iter 470: train loss 0.51624. lr 3.5771e-04: 100%|████████████████████████████████████████████████████████████████████████████████| 471/471 [00:05<00:00, 84.92it/s]
test loss: %f 0.4742305424978148
step_train_loss: 0.5971682071685791 train_step: 6500, learning_rate: 0.00035250016181074135██████████████████████████████▋                 | 369/471 [00:04<00:01, 85.55it/s]
epoch 14 iter 470: train loss 0.68497. lr 3.5119e-04: 100%|████████████████████████████████████████████████████████████████████████████████| 471/471 [00:05<00:00, 78.58it/s]
test loss: %f 0.46179794477966596
epoch 15 iter 24: train loss 0.56392. lr 3.5083e-04:   4%|███▏                                                                              | 18/471 [00:00<0epoch 15 iter 25: train loss 0.50696. lr 3.5081e-04:   4%|███▏                                                                              | 18/471 [00:00<0epoch 15 iter 25: train loss 0.50696. lr 3.5081e-04:   6%|████▌                                                                             | 26/471 [00:00<0epoch 15 iter 26: train loss 0.54664. lr 3.5080e-04:   6%|████▌                                                                             | 26/471 [00:00<0epoch 15 iter 27: train loss 0.69346. lr 3.5079e-04:   6%|████▌                                                                             | 26/471 [00:00<0epoch 15 iter 28: train loss 0.61130. lr 3.5077e-04:   6%|████▌                                                                             | 26/471 [00:00<0epoch 15 iter 29: train loss 0.46416. lr 3.5076e-04:   6%|████▌                                                                             | 26/471 [00:00<0epoch 15 iter 30: train loss 0.55503. lr 3.5074e-04:   6%|████▌                                                                             | 26/471 [00:00<0epoch 15 iter 31: train loss 0.60196. lr 3.5073e-04:   6%|████▌                                                                             | 26/471 [00:00<0epoch 15 iter 32: train loss 0.49860. lr 3.5071e-04:   6%|████▌                                                                             | 26/471 [00:00<0epoch 15 iter 32: train loss 0.49860. lr 3.5071e-04:   7%|█████▋                                                                            | 33/471 [00:00<0epoch 15 iter 33: train loss 0.54746. lr 3.5070e-04:   7%|█████▋                                                                            | 33/471 [00:00<0epoch 15 iter 34: train loss 0.63059. lr 3.5069e-04:   7%|█████▋                                                                            | 33/471 [00:00<0epoch 15 iter 35: train loss 0.61266. lr 3.5067e-04:   7%|█████▋                                                                            | 33/471 [00:00<0epoch 15 iter 36: train loss 0.60448. lr 3.5066e-04:   7%|█████▋                                                                            | 33/471 [00:00<0epoch 15 iter 37: train loss 0.55307. lr 3.5064e-04:   7%|█████▋                                                                            | 33/471 [00:00<0epoch 15 iter 38: train loss 0.63106. lr 3.5063e-04:   7%|█████▋                                                                            | 33/471 [00:00<0epoch 15 iter 39: train loss 0.50713. lr 3.5061e-04:   7%|█████▋                                                                            | 33/471 [00:00<0epoch 15 iter 40: train loss 0.61758. lr 3.5060e-04:   7%|█████▋                                                                            | 33/471 [00:00<0epoch 15 iter 40: train loss 0.61758. lr 3.5060e-04:   9%|███████▏                                                                          | 41/471 [00:00<0epoch 15 iter 41: train loss 0.67778. lr 3.5058e-04:   9%|███████▏                                                                          | 41/471 [00:00<0epoch 15 iter 42: train loss 0.65231. lr 3.5057e-04:   9%|███████▏                                                                          | 41/471 [00:00<0epoch 15 iter 43: train loss 0.49682. lr 3.5056e-04:   9%|███████▏                                                                          | 41/471 [00:00<0epoch 15 iter 44: train loss 0.69091. lr 3.5054e-04:   9%|███████▏                                                                          | 41/471 [00:00<0epoch 15 iter 45: train loss 0.60664. lr 3.5053e-04:   9%|███████▏                                                                          | 41/471 [00:00<0epoch 15 iter 46: train loss 0.72027. lr 3.5051e-04:   9%|███████▏                                                                          | 41/471 [00:00<0epoch 15 iter 47: train loss 0.59009. lr 3.5050e-04:   9%|███████▏                                                                          | 41/471 [00:00<0epoch 15 iter 48: train loss 0.61564. lr 3.5048e-04:   9%|███████▏                                                                          | 41/471 [00:00<0epoch 15 iter 48: train loss 0.61564. lr 3.5048e-04:  10%|████████▌                                                                         | 49/471 [00:00<0epoch 15 iter 49: train loss 0.61914. lr 3.5047e-04:  10%|████████▌                                                                         | 49/471 [00:00<0epoch 15 iter 50: train loss 0.59028. lr 3.5046e-04:  10%|████████▌                                                                         | 49/471 [00:00<0epoch 15 iter 51: train loss 0.69216. lr 3.5044e-04:  10%|████████▌                                                                         | 49/471 [00:00<0epoch 15 iter 52: train loss 0.54495. lr 3.5043e-04:  10%|████████▌                                                                         | 49/471 [00:00<0epoch 15 iter 53: train loss 0.62445. lr 3.5041e-04:  10%|████████▌                                                                         | 49/471 [00:00<0epoch 15 iter 54: train loss 0.55502. lr 3.5040e-04:  10%|████████▌                                                                         | 49/471 [00:00<0epoch 15 iter 55: train loss 0.48929. lr 3.5038e-04:  10%|████████▌                                                                         | 49/471 [00:00<0epoch 15 iter 56: train loss 0.51804. lr 3.5037e-04:  10%|████████▌                                                                         | 49/471 [00:00<0epoch 15 iter 57: train loss 0.60650. lr 3.5035e-04:  10%|████████▌                                                                         | 49/471 [00:00<0epoch 15 iter 57: train loss 0.60650. lr 3.5035e-04:  12%|██████████                                                                        | 58/471 [00:00<0epoch 15 iter 58: train loss 0.57805. lr 3.5034e-04:  12%|██████████                                                                        | 58/471 [00:00<0epoch 15 iter 59: train loss 0.61735. lr 3.5033e-04:  12%|██████████                                                                        | 58/471 [00:00<0epoch 15 iter 60: train loss 0.72887. lr 3.5031e-04:  12%|██████████                                                                        | 58/471 [00:00<0epoch 15 iter 61: train loss 0.51658. lr 3.5030e-04:  12%|██████████                                                                        | 58/471 [00:00<0epoch 15 iter 62: train loss 0.55281. lr 3.5028e-04:  12%|██████████                                                                        | 58/471 [00:00<0epoch 15 iter 63: train loss 0.53703. lr 3.5027e-04:  12%|██████████                                                                        | 58/471 [00:00<0epoch 15 iter 64: train loss 0.54574. lr 3.5025e-04:  12%|██████████                                                                        | 58/471 [00:00<0epoch 15 iter 65: train loss 0.61827. lr 3.5024e-04:  12%|██████████                                                                        | 58/471 [00:00<0epoch 15 iter 65: train loss 0.61827. lr 3.5024e-04:  14%|███████████▍                                                                      | 66/471 [00:00<0epoch 15 iter 66: train loss 0.60881. lr 3.5022e-04:  14%|███████████▍                                                                      | 66/471 [00:00<0epoch 15 iter 67: train loss 0.55094. lr 3.5021e-04:  14%|███████████▍                                                                      | 66/471 [00:00<0epoch 15 iter 68: train loss 0.60293. lr 3.5020e-04:  14%|███████████▍                                                                      | 66/471 [00:00<0epoch 15 iter 69: train loss 0.49311. lr 3.5018e-04:  14%|███████████▍                                                                      | 66/471 [00:01<0epoch 15 iter 70: train loss 0.63276. lr 3.5017e-04:  14%|███████████▍                                                                      | 66/471 [00:01<0epoch 15 iter 71: train loss 0.60091. lr 3.5015e-04:  14%|███████████▍                                                                      | 66/471 [00:01<0epoch 15 iter 72: train loss 0.58634. lr 3.5014e-04:  14%|███████████▍                                                                      | 66/471 [00:01<0epoch 15 iter 73: train loss 0.58126. lr 3.5012e-04:  14%|███████████▍                                                                      | 66/471 [00:01<0epoch 15 iter 73: train loss 0.58126. lr 3.5012e-04:  16%|████████████▉                                                                     | 74/471 [00:01<0epoch 15 iter 74: train loss 0.60804. lr 3.5011e-04:  16%|████████████▉                                                                     | 74/471 [00:01<0epoch 15 iter 75: train loss 0.50804. lr 3.5009e-04:  16%|████████████▉                                                                     | 74/471 [00:01<0epoch 15 iter 76: train loss 0.58929. lr 3.5008e-04:  16%|████████████▉                                                                     | 74/471 [00:01<0epoch 15 iter 77: train loss 0.64056. lr 3.5007e-04:  16%|████████████▉                                                                     | 74/471 [00:01<0epoch 15 iter 78: train loss 0.59401. lr 3.5005e-04:  16%|████████████▉                                                                     | 74/471 [00:01<0epoch 15 iter 79: train loss 0.62493. lr 3.5004e-04:  16%|████████████▉                                                                     | 74/471 [00:01<0epoch 15 iter 80: train loss 0.50220. lr 3.5002e-04:  16%|████████████▉                                                                     | 74/471 [00:01<0epoch 15 iter 81: train loss 0.61928. lr 3.5001e-04:  16%|████████████▉                                                                     | 74/471 [00:01<0epoch 15 iter 81: train loss 0.61928. lr 3.5001e-04:  17%|██████████████▎                                                                   | 82/471 [00:01<0epoch 15 iter 82: train loss 0.55846. lr 3.4999e-04:  17%|██████████████▎                                                                   | 82/471 [00:01<0epoch 15 iter 83: train loss 0.62827. lr 3.4998e-04:  17%|██████████████▎                                                                   | 82/471 [00:01<0epoch 15 iter 84: train loss 0.66694. lr 3.4997e-04:  17%|██████████████▎                                                                   | 82/471 [00:01<0epoch 15 iter 85: train loss 0.55914. lr 3.4995e-04:  17%|██████████████▎                                                                   | 82/471 [00:01<0epoch 15 iter 86: train loss 0.47888. lr 3.4994e-04:  17%|██████████████▎                                                                   | 82/471 [00:01<0epoch 15 iter 87: train loss 0.57574. lr 3.4992e-04:  17%|██████████████▎                                                                   | 82/471 [00:01<0epoch 15 iter 88: train loss 0.60396. lr 3.4991e-04:  17%|██████████████▎                                                                   | 82/471 [00:01<0epoch 15 iter 89: train loss 0.59466. lr 3.4989e-04:  17%|██████████████▎                                                                   | 82/471 [00:01<0epoch 15 iter 90: train loss 0.53618. lr 3.4988e-04:  17%|██████████████▎                                                                   | 82/471 [00:01<0epoch 15 iter 90: train loss 0.53618. lr 3.4988e-04:  19%|███████████████▊                                                                  | 91/471 [00:01<0epoch 15 iter 91: train loss 0.60051. lr 3.4986e-04:  19%|███████████████▊                                                                  | 91/471 [00:01<0epoch 15 iter 92: train loss 0.57777. lr 3.4985e-04:  19%|███████████████▊                                                                  | 91/471 [00:01<0epoch 15 iter 93: train loss 0.51706. lr 3.4983e-04:  19%|███████████████▊                                                                  | 91/471 [00:01<0epoch 15 iter 94: train loss 0.63616. lr 3.4982e-04:  19%|███████████████▊                                                                  | 91/471 [00:01<0epoch 15 iter 95: train loss 0.61577. lr 3.4981e-04:  19%|███████████████▊                                                                  | 91/471 [00:01<0epoch 15 iter 96: train loss 0.66201. lr 3.4979e-04:  19%|███████████████▊                                                                  | 91/471 [00:01<0epoch 15 iter 97: train loss 0.65800. lr 3.4978e-04:  19%|███████████████▊                                                                  | 91/471 [00:01<0epoch 15 iter 98: train loss 0.60500. lr 3.4976e-04:  19%|███████████████▊                                                                  | 91/471 [00:01<0epoch 15 iter 98: train loss 0.60500. lr 3.4976e-04:  21%|█████████████████▏                                                                | 99/471 [00:01<0epoch 15 iter 99: train loss 0.64050. lr 3.4975e-04:  21%|█████████████████▏                                                                | 99/471 [00:01<0epoch 15 iter 100: train loss 0.53133. lr 3.4973e-04:  21%|█████████████████                                                                | 99/471 [00:01<0epoch 15 iter 101: train loss 0.51189. lr 3.4972e-04:  21%|█████████████████                                                                | 99/471 [00:01<0epoch 15 iter 102: train loss 0.47733. lr 3.4970e-04:  21%|█████████████████                                                                | 99/471 [00:01<0epoch 15 iter 103: train loss 0.65593. lr 3.4969e-04:  21%|█████████████████                                                                | 99/471 [00:01<0epoch 15 iter 104: train loss 0.70974. lr 3.4968e-04:  21%|█████████████████                                                                | 99/471 [00:01<0epoch 15 iter 105: train loss 0.50810. lr 3.4966e-04:  21%|█████████████████                                                                | 99/471 [00:01<0epoch 15 iter 106: train loss 0.48797. lr 3.4965e-04:  21%|█████████████████                                                                | 99/471 [00:01<0epoch 15 iter 106: train loss 0.48797. lr 3.4965e-04:  23%|██████████████████▏                                                             | 107/471 [00:01<0epoch 15 iter 107: train loss 0.58636. lr 3.4963e-04:  23%|██████████████████▏                                                             | 107/471 [00:01<0epoch 15 iter 108: train loss 0.61910. lr 3.4962e-04:  23%|██████████████████▏                                                             | 107/471 [00:01<0epoch 15 iter 109: train loss 0.57117. lr 3.4960e-04:  23%|██████████████████▏                                                             | 107/471 [00:01<0epoch 15 iter 110: train loss 0.57668. lr 3.4959e-04:  23%|██████████████████▏                                                             | 107/471 [00:01<0epoch 15 iter 111: train loss 0.65319. lr 3.4957e-04:  23%|██████████████████▏                                                             | 107/471 [00:01<0epoch 15 iter 112: train loss 0.57340. lr 3.4956e-04:  23%|██████████████████▏                                                             | 107/471 [00:01<0epoch 15 iter 113: train loss 0.54270. lr 3.4955e-04:  23%|██████████████████▏                                                             | 107/471 [00:01<0epoch 15 iter 114: train loss 0.59591. lr 3.4953e-04:  23%|██████████████████▏                                                             | 107/471 [00:01<0epoch 15 iter 115: train loss 0.52232. lr 3.4952e-04:  23%|██████████████████▏                                                             | 107/471 [00:01<0epoch 15 iter 115: train loss 0.52232. lr 3.4952e-04:  25%|███████████████████▋                                                            | 116/471 [00:01<0epoch 15 iter 116: train loss 0.59562. lr 3.4950e-04:  25%|███████████████████▋                                                            | 116/471 [00:01<0epoch 15 iter 117: train loss 0.64645. lr 3.4949e-04:  25%|███████████████████▋                                                            | 116/471 [00:01<0epoch 15 iter 118: train loss 0.61369. lr 3.4947e-04:  25%|███████████████████▋                                                            | 116/471 [00:01<0epoch 15 iter 119: train loss 0.54035. lr 3.4946e-04:  25%|███████████████████▋                                                            | 116/471 [00:01<0epoch 15 iter 120: train loss 0.67358. lr 3.4944e-04:  25%|███████████████████▋                                                            | 116/471 [00:01<0epoch 15 iter 121: train loss 0.57980. lr 3.4943e-04:  25%|███████████████████▋                                                            | 116/471 [00:01<0epoch 15 iter 122: train loss 0.52759. lr 3.4941e-04:  25%|███████████████████▋                                                            | 116/471 [00:01<0epoch 15 iter 123: train loss 0.57221. lr 3.4940e-04:  25%|███████████████████▋                                                            | 116/471 [00:01<0epoch 15 iter 123: train loss 0.57221. lr 3.4940e-04:  26%|█████████████████████                                                           | 124/471 [00:01<0epoch 15 iter 124: train loss 0.53137. lr 3.4939e-04:  26%|█████████████████████                                                           | 124/471 [00:01<0epoch 15 iter 125: train loss 0.56832. lr 3.4937e-04:  26%|█████████████████████                                                           | 124/471 [00:01<0epoch 15 iter 126: train loss 0.62341. lr 3.4936e-04:  26%|█████████████████████                                                           | 124/471 [00:01<0epoch 15 iter 127: train loss 0.56635. lr 3.4934e-04:  26%|█████████████████████                                                           | 124/471 [00:01<0epoch 15 iter 128: train loss 0.66507. lr 3.4933e-04:  26%|█████████████████████                                                           | 124/471 [00:01<0epoch 15 iter 129: train loss 0.55205. lr 3.4931e-04:  26%|█████████████████████                                                           | 124/471 [00:01<0epoch 15 iter 130: train loss 0.67007. lr 3.4930e-04:  26%|█████████████████████                                                           | 124/471 [00:01<0epoch 15 iter 131: train loss 0.49910. lr 3.4928e-04:  26%|█████████████████████                                                           | 124/471 [00:01<0epoch 15 iter 131: train loss 0.49910. lr 3.4928e-04:  28%|██████████████████████▍                                                         | 132/471 [00:01<0epoch 15 iter 132: train loss 0.53627. lr 3.4927e-04:  28%|██████████████████████▍                                                         | 132/471 [00:01<0epoch 15 iter 133: train loss 0.60983. lr 3.4926e-04:  28%|██████████████████████▍                                                         | 132/471 [00:01<0epoch 15 iter 134: train loss 0.67101. lr 3.4924e-04:  28%|██████████████████████▍                                                         | 132/471 [00:01<0epoch 15 iter 135: train loss 0.53704. lr 3.4923e-04:  28%|██████████████████████▍                                                         | 132/471 [00:01<0epoch 15 iter 136: train loss 0.63491. lr 3.4921e-04:  28%|██████████████████████▍                                                         | 132/471 [00:01<0epoch 15 iter 137: train loss 0.51480. lr 3.4920e-04:  28%|██████████████████████▍                                                         | 132/471 [00:01<0epoch 15 iter 138: train loss 0.52240. lr 3.4918e-04:  28%|██████████████████████▍                                                         | 132/471 [00:01<0epoch 15 iter 139: train loss 0.61829. lr 3.4917e-04:  28%|██████████████████████▍                                                         | 132/471 [00:01<0epoch 15 iter 139: train loss 0.61829. lr 3.4917e-04:  30%|███████████████████████▊                                                        | 140/471 [00:01<0epoch 15 iter 140: train loss 0.60231. lr 3.4915e-04:  30%|███████████████████████▊                                                        | 140/471 [00:01<0epoch 15 iter 141: train loss 0.70001. lr 3.4914e-04:  30%|███████████████████████▊                                                        | 140/471 [00:01<0epoch 15 iter 142: train loss 0.52662. lr 3.4912e-04:  30%|███████████████████████▊                                                        | 140/471 [00:01<0epoch 15 iter 143: train loss 0.57358. lr 3.4911e-04:  30%|███████████████████████▊                                                        | 140/471 [00:01<0epoch 15 iter 144: train loss 0.61569. lr 3.4910e-04:  30%|███████████████████████▊                                                        | 140/471 [00:01<0epoch 15 iter 145: train loss 0.58283. lr 3.4908e-04:  30%|███████████████████████▊                                                        | 140/471 [00:01<0epoch 15 iter 146: train loss 0.55602. lr 3.4907e-04:  30%|███████████████████████▊                                                        | 140/471 [00:01<0epoch 15 iter 147: train loss 0.65951. lr 3.4905e-04:  30%|███████████████████████▊                                                        | 140/471 [00:01<0epoch 15 iter 148: train loss 0.51138. lr 3.4904e-04:  30%|███████████████████████▊                                                        | 140/471 [00:02<0epoch 15 iter 148: train loss 0.51138. lr 3.4904e-04:  32%|█████████████████████████▎                                                      | 149/471 [00:02<0epoch 15 iter 149: train loss 0.56373. lr 3.4902e-04:  32%|█████████████████████████▎                                                      | 149/471 [00:02<0epoch 15 iter 150: train loss 0.63012. lr 3.4901e-04:  32%|█████████████████████████▎                                                      | 149/471 [00:02<0epoch 15 iter 151: train loss 0.51113. lr 3.4899e-04:  32%|█████████████████████████▎                                                      | 149/471 [00:02<0epoch 15 iter 152: train loss 0.54545. lr 3.4898e-04:  32%|█████████████████████████▎                                                      | 149/471 [00:02<0epoch 15 iter 153: train loss 0.56436. lr 3.4896e-04:  32%|█████████████████████████▎                                                      | 149/471 [00:02<0epoch 15 iter 154: train loss 0.49647. lr 3.4895e-04:  32%|█████████████████████████▎                                                      | 149/471 [00:02<0epoch 15 iter 155: train loss 0.55197. lr 3.4893e-04:  32%|█████████████████████████▎                                                      | 149/471 [00:02<0epoch 15 iter 156: train loss 0.58261. lr 3.4892e-04:  32%|█████████████████████████▎                                                      | 149/471 [00:02<0epoch 15 iter 157: train loss 0.67751. lr 3.4891e-04:  32%|█████████████████████████▎                                                      | 149/471 [00:02<0epoch 15 iter 157: train loss 0.67751. lr 3.4891e-04:  34%|██████████████████████████▊                                                     | 158/471 [00:02<0epoch 15 iter 158: train loss 0.58226. lr 3.4889e-04:  34%|██████████████████████████▊                                                     | 158/471 [00:02<0epoch 15 iter 159: train loss 0.64359. lr 3.4888e-04:  34%|██████████████████████████▊                                                     | 158/471 [00:02<0epoch 15 iter 160: train loss 0.62618. lr 3.4886e-04:  34%|██████████████████████████▊                                                     | 158/471 [00:02<0epoch 15 iter 161: train loss 0.57348. lr 3.4885e-04:  34%|██████████████████████████▊                                                     | 158/471 [00:02<0epoch 15 iter 162: train loss 0.64243. lr 3.4883e-04:  34%|██████████████████████████▊                                                     | 158/471 [00:02<0epoch 15 iter 163: train loss 0.59859. lr 3.4882e-04:  34%|██████████████████████████▊                                                     | 158/471 [00:02<0epoch 15 iter 164: train loss 0.62873. lr 3.4880e-04:  34%|██████████████████████████▊                                                     | 158/471 [00:02<0epoch 15 iter 165: train loss 0.56405. lr 3.4879e-04:  34%|██████████████████████████▊                                                     | 158/471 [00:02<0epoch 15 iter 166: train loss 0.53770. lr 3.4877e-04:  34%|██████████████████████████▊                                                     | 158/471 [00:02<0epoch 15 iter 166: train loss 0.53770. lr 3.4877e-04:  35%|████████████████████████████▎                                                   | 167/471 [00:02<0epoch 15 iter 167: train loss 0.58113. lr 3.4876e-04:  35%|████████████████████████████▎                                                   | 167/471 [00:02<0epoch 15 iter 168: train loss 0.54257. lr 3.4875e-04:  35%|████████████████████████████▎                                                   | 167/471 [00:02<0epoch 15 iter 169: train loss 0.58037. lr 3.4873e-04:  35%|████████████████████████████▎                                                   | 167/471 [00:02<0epoch 15 iter 170: train loss 0.52338. lr 3.4872e-04:  35%|████████████████████████████▎                                                   | 167/471 [00:02<0epoch 15 iter 171: train loss 0.43022. lr 3.4870e-04:  35%|████████████████████████████▎                                                   | 167/471 [00:02<0epoch 15 iter 172: train loss 0.57886. lr 3.4869e-04:  35%|████████████████████████████▎                                                   | 167/471 [00:02<0epoch 15 iter 173: train loss 0.53781. lr 3.4867e-04:  35%|████████████████████████████▎                                                   | 167/471 [00:02<0epoch 15 iter 174: train loss 0.47902. lr 3.4866e-04:  35%|████████████████████████████▎                                                   | 167/471 [00:02<0epoch 15 iter 175: train loss 0.59958. lr 3.4864e-04:  35%|████████████████████████████▎                                                   | 167/471 [00:02<0epoch 15 iter 175: train loss 0.59958. lr 3.4864e-04:  37%|█████████████████████████████▉                                                  | 176/471 [00:02<0epoch 15 iter 176: train loss 0.63803. lr 3.4863e-04:  37%|█████████████████████████████▉                                                  | 176/471 [00:02<0epoch 15 iter 177: train loss 0.61580. lr 3.4861e-04:  37%|█████████████████████████████▉                                                  | 176/471 [00:02<0epoch 15 iter 178: train loss 0.56683. lr 3.4860e-04:  37%|█████████████████████████████▉                                                  | 176/471 [00:02<0epoch 15 iter 179: train loss 0.51327. lr 3.4858e-04:  37%|█████████████████████████████▉                                                  | 176/471 [00:02<0epoch 15 iter 180: train loss 0.60460. lr 3.4857e-04:  37%|█████████████████████████████▉                                                  | 176/471 [00:02<0epoch 15 iter 181: train loss 0.57495. lr 3.4856e-04:  37%|█████████████████████████████▉                                                  | 176/471 [00:02<0epoch 15 iter 182: train loss 0.64877. lr 3.4854e-04:  37%|█████████████████████████████▉                                                  | 176/471 [00:02<0epoch 15 iter 183: train loss 0.66767. lr 3.4853e-04:  37%|█████████████████████████████▉                                                  | 176/471 [00:02<0epoch 15 iter 184: train loss 0.71696. lr 3.4851e-04:  37%|█████████████████████████████▉                                                  | 176/471 [00:02<0epoch 15 iter 184: train loss 0.71696. lr 3.4851e-04:  39%|███████████████████████████████▍                                                | 185/471 [00:02<0epoch 15 iter 185: train loss 0.61073. lr 3.4850e-04:  39%|███████████████████████████████▍                                                | 185/471 [00:02<0epoch 15 iter 186: train loss 0.66467. lr 3.4848e-04:  39%|███████████████████████████████▍                                                | 185/471 [00:02<0epoch 15 iter 187: train loss 0.64852. lr 3.4847e-04:  39%|███████████████████████████████▍                                                | 185/471 [00:02<0epoch 15 iter 188: train loss 0.55102. lr 3.4845e-04:  39%|███████████████████████████████▍                                                | 185/471 [00:02<0epoch 15 iter 189: train loss 0.54489. lr 3.4844e-04:  39%|███████████████████████████████▍                                                | 185/471 [00:02<0epoch 15 iter 190: train loss 0.61905. lr 3.4842e-04:  39%|███████████████████████████████▍                                                | 185/471 [00:02<0epoch 15 iter 191: train loss 0.60502. lr 3.4841e-04:  39%|███████████████████████████████▍                                                | 185/471 [00:02<0epoch 15 iter 192: train loss 0.57637. lr 3.4839e-04:  39%|███████████████████████████████▍                                                | 185/471 [00:02<0epoch 15 iter 193: train loss 0.68923. lr 3.4838e-04:  39%|███████████████████████████████▍                                                | 185/471 [00:02<0epoch 15 iter 193: train loss 0.68923. lr 3.4838e-04:  41%|████████████████████████████████▉                                               | 194/471 [00:02<0epoch 15 iter 194: train loss 0.55657. lr 3.4837e-04:  41%|████████████████████████████████▉                                               | 194/471 [00:02<0epoch 15 iter 195: train loss 0.64192. lr 3.4835e-04:  41%|████████████████████████████████▉                                               | 194/471 [00:02<0epoch 15 iter 196: train loss 0.61658. lr 3.4834e-04:  41%|████████████████████████████████▉                                               | 194/471 [00:02<0epoch 15 iter 197: train loss 0.55129. lr 3.4832e-04:  41%|████████████████████████████████▉                                               | 194/471 [00:02<0epoch 15 iter 198: train loss 0.58668. lr 3.4831e-04:  41%|████████████████████████████████▉                                               | 194/471 [00:02<0epoch 15 iter 199: train loss 0.54739. lr 3.4829e-04:  41%|████████████████████████████████▉                                               | 194/471 [00:02<0epoch 15 iter 200: train loss 0.52493. lr 3.4828e-04:  41%|████████████████████████████████▉                                               | 194/471 [00:02<0epoch 15 iter 201: train loss 0.60626. lr 3.4826e-04:  41%|████████████████████████████████▉                                               | 194/471 [00:02<0epoch 15 iter 202: train loss 0.54268. lr 3.4825e-04:  41%|████████████████████████████████▉                                               | 194/471 [00:02<0epoch 15 iter 202: train loss 0.54268. lr 3.4825e-04:  43%|██████████████████████████████████▍                                             | 203/471 [00:02<0epoch 15 iter 203: train loss 0.49417. lr 3.4823e-04:  43%|██████████████████████████████████▍                                             | 203/471 [00:02<0epoch 15 iter 204: train loss 0.60226. lr 3.4822e-04:  43%|██████████████████████████████████▍                                             | 203/471 [00:02<0epoch 15 iter 205: train loss 0.59888. lr 3.4820e-04:  43%|██████████████████████████████████▍                                             | 203/471 [00:02<0epoch 15 iter 206: train loss 0.58966. lr 3.4819e-04:  43%|██████████████████████████████████▍                                             | 203/471 [00:02<0epoch 15 iter 207: train loss 0.62806. lr 3.4817e-04:  43%|██████████████████████████████████▍                                             | 203/471 [00:02<0epoch 15 iter 208: train loss 0.67956. lr 3.4816e-04:  43%|██████████████████████████████████▍                                             | 203/471 [00:02<0epoch 15 iter 209: train loss 0.51304. lr 3.4815e-04:  43%|██████████████████████████████████▍                                             | 203/471 [00:02<0epoch 15 iter 210: train loss 0.63739. lr 3.4813e-04:  43%|██████████████████████████████████▍                                             | 203/471 [00:02<0epoch 15 iter 211: train loss 0.66757. lr 3.4812e-04:  43%|██████████████████████████████████▍                                             | 203/471 [00:02<0epoch 15 iter 211: train loss 0.66757. lr 3.4812e-04:  45%|████████████████████████████████████                                            | 212/471 [00:02<0epoch 15 iter 212: train loss 0.60090. lr 3.4810e-04:  45%|████████████████████████████████████                                            | 212/471 [00:02<0epoch 15 iter 213: train loss 0.60028. lr 3.4809e-04:  45%|████████████████████████████████████                                            | 212/471 [00:02<0epoch 15 iter 214: train loss 0.59564. lr 3.4807e-04:  45%|████████████████████████████████████                                            | 212/471 [00:02<0epoch 15 iter 215: train loss 0.70555. lr 3.4806e-04:  45%|████████████████████████████████████                                            | 212/471 [00:02<0epoch 15 iter 216: train loss 0.53762. lr 3.4804e-04:  45%|████████████████████████████████████                                            | 212/471 [00:02<0epoch 15 iter 217: train loss 0.62889. lr 3.4803e-04:  45%|████████████████████████████████████                                            | 212/471 [00:02<0epoch 15 iter 218: train loss 0.59642. lr 3.4801e-04:  45%|████████████████████████████████████                                            | 212/471 [00:02<0epoch 15 iter 219: train loss 0.52099. lr 3.4800e-04:  45%|████████████████████████████████████                                            | 212/471 [00:02<0epoch 15 iter 220: train loss 0.55429. lr 3.4798e-04:  45%|████████████████████████████████████                                            | 212/471 [00:02<0epoch 15 iter 220: train loss 0.55429. lr 3.4798e-04:  47%|█████████████████████████████████████▌                                          | 221/471 [00:02<0epoch 15 iter 221: train loss 0.78363. lr 3.4797e-04:  47%|█████████████████████████████████████▌                                          | 221/471 [00:02<0epoch 15 iter 222: train loss 0.53068. lr 3.4795e-04:  47%|█████████████████████████████████████▌                                          | 221/471 [00:02<0epoch 15 iter 223: train loss 0.55155. lr 3.4794e-04:  47%|█████████████████████████████████████▌                                          | 221/471 [00:02<0epoch 15 iter 224: train loss 0.44020. lr 3.4793e-04:  47%|█████████████████████████████████████▌                                          | 221/471 [00:02<0epoch 15 iter 225: train loss 0.63860. lr 3.4791e-04:  47%|█████████████████████████████████████▌                                          | 221/471 [00:02<0epoch 15 iter 226: train loss 0.46705. lr 3.4790e-04:  47%|█████████████████████████████████████▌                                          | 221/471 [00:02<0epoch 15 iter 227: train loss 0.67560. lr 3.4788e-04:  47%|█████████████████████████████████████▌                                          | 221/471 [00:02<0epoch 15 iter 228: train loss 0.60738. lr 3.4787e-04:  47%|█████████████████████████████████████▌                                          | 221/471 [00:02<0epoch 15 iter 229: train loss 0.60914. lr 3.4785e-04:  47%|█████████████████████████████████████▌                                          | 221/471 [00:03<0epoch 15 iter 229: train loss 0.60914. lr 3.4785e-04:  49%|███████████████████████████████████████                                         | 230/471 [00:03<0epoch 15 iter 230: train loss 0.64022. lr 3.4784e-04:  49%|███████████████████████████████████████                                         | 230/471 [00:03<0epoch 15 iter 231: train loss 0.55524. lr 3.4782e-04:  49%|███████████████████████████████████████                                         | 230/471 [00:03<0epoch 15 iter 232: train loss 0.62880. lr 3.4781e-04:  49%|███████████████████████████████████████                                         | 230/471 [00:03<0epoch 15 iter 233: train loss 0.58774. lr 3.4779e-04:  49%|███████████████████████████████████████                                         | 230/471 [00:03<0epoch 15 iter 234: train loss 0.62461. lr 3.4778e-04:  49%|███████████████████████████████████████                                         | 230/471 [00:03<0epoch 15 iter 235: train loss 0.61612. lr 3.4776e-04:  49%|███████████████████████████████████████                                         | 230/471 [00:03<0epoch 15 iter 236: train loss 0.47018. lr 3.4775e-04:  49%|███████████████████████████████████████                                         | 230/471 [00:03<0epoch 15 iter 237: train loss 0.59213. lr 3.4773e-04:  49%|███████████████████████████████████████                                         | 230/471 [00:03<0epoch 15 iter 238: train loss 0.54633. lr 3.4772e-04:  49%|███████████████████████████████████████                                         | 230/471 [00:03<0epoch 15 iter 238: train loss 0.54633. lr 3.4772e-04:  51%|████████████████████████████████████████▌                                       | 239/471 [00:03<0epoch 15 iter 239: train loss 0.56021. lr 3.4770e-04:  51%|████████████████████████████████████████▌                                       | 239/471 [00:03<0epoch 15 iter 240: train loss 0.57986. lr 3.4769e-04:  51%|████████████████████████████████████████▌                                       | 239/471 [00:03<0epoch 15 iter 241: train loss 0.50484. lr 3.4768e-04:  51%|████████████████████████████████████████▌                                       | 239/471 [00:03<0epoch 15 iter 242: train loss 0.58659. lr 3.4766e-04:  51%|████████████████████████████████████████▌                                       | 239/471 [00:03<0epoch 15 iter 243: train loss 0.71599. lr 3.4765e-04:  51%|████████████████████████████████████████▌                                       | 239/471 [00:03<0epoch 15 iter 244: train loss 0.48045. lr 3.4763e-04:  51%|████████████████████████████████████████▌                                       | 239/471 [00:03<0epoch 15 iter 245: train loss 0.59229. lr 3.4762e-04:  51%|████████████████████████████████████████▌                                       | 239/471 [00:03<0epoch 15 iter 246: train loss 0.63528. lr 3.4760e-04:  51%|████████████████████████████████████████▌                                       | 239/471 [00:03<0epoch 15 iter 247: train loss 0.59344. lr 3.4759e-04:  51%|████████████████████████████████████████▌                                       | 239/471 [00:03<0epoch 15 iter 247: train loss 0.59344. lr 3.4759e-04:  53%|██████████████████████████████████████████                                      | 248/471 [00:03<0epoch 15 iter 248: train loss 0.61103. lr 3.4757e-04:  53%|██████████████████████████████████████████                                      | 248/471 [00:03<0epoch 15 iter 249: train loss 0.51971. lr 3.4756e-04:  53%|██████████████████████████████████████████                                      | 248/471 [00:03<0epoch 15 iter 250: train loss 0.54533. lr 3.4754e-04:  53%|██████████████████████████████████████████                                      | 248/471 [00:03<0epoch 15 iter 251: train loss 0.53752. lr 3.4753e-04:  53%|██████████████████████████████████████████                                      | 248/471 [00:03<0epoch 15 iter 252: train loss 0.52573. lr 3.4751e-04:  53%|██████████████████████████████████████████                                      | 248/471 [00:03<0epoch 15 iter 253: train loss 0.63425. lr 3.4750e-04:  53%|██████████████████████████████████████████                                      | 248/471 [00:03<0epoch 15 iter 254: train loss 0.52919. lr 3.4748e-04:  53%|██████████████████████████████████████████                                      | 248/471 [00:03<0epoch 15 iter 255: train loss 0.67656. lr 3.4747e-04:  53%|██████████████████████████████████████████                                      | 248/471 [00:03<0epoch 15 iter 256: train loss 0.61817. lr 3.4745e-04:  53%|██████████████████████████████████████████                                      | 248/471 [00:03<0epoch 15 iter 256: train loss 0.61817. lr 3.4745e-04:  55%|███████████████████████████████████████████▋                                    | 257/471 [00:03<0epoch 15 iter 257: train loss 0.57718. lr 3.4744e-04:  55%|███████████████████████████████████████████▋                                    | 257/471 [00:03<0epoch 15 iter 258: train loss 0.58836. lr 3.4742e-04:  55%|███████████████████████████████████████████▋                                    | 257/471 [00:03<0epoch 15 iter 259: train loss 0.59560. lr 3.4741e-04:  55%|███████████████████████████████████████████▋                                    | 257/471 [00:03<0epoch 15 iter 260: train loss 0.55590. lr 3.4740e-04:  55%|███████████████████████████████████████████▋                                    | 257/471 [00:03<0epoch 15 iter 261: train loss 0.56906. lr 3.4738e-04:  55%|███████████████████████████████████████████▋                                    | 257/471 [00:03<0epoch 15 iter 262: train loss 0.57800. lr 3.4737e-04:  55%|███████████████████████████████████████████▋                                    | 257/471 [00:03<0epoch 15 iter 263: train loss 0.74236. lr 3.4735e-04:  55%|███████████████████████████████████████████▋                                    | 257/471 [00:03<0epoch 15 iter 264: train loss 0.63987. lr 3.4734e-04:  55%|███████████████████████████████████████████▋                                    | 257/471 [00:03<0epoch 15 iter 265: train loss 0.53903. lr 3.4732e-04:  55%|███████████████████████████████████████████▋                                    | 257/471 [00:03<0epoch 15 iter 265: train loss 0.53903. lr 3.4732e-04:  56%|█████████████████████████████████████████████▏                                  | 266/471 [00:03<0epoch 15 iter 266: train loss 0.54936. lr 3.4731e-04:  56%|█████████████████████████████████████████████▏                                  | 266/471 [00:03<0epoch 15 iter 267: train loss 0.53179. lr 3.4729e-04:  56%|█████████████████████████████████████████████▏                                  | 266/471 [00:03<0epoch 15 iter 268: train loss 0.55892. lr 3.4728e-04:  56%|█████████████████████████████████████████████▏                                  | 266/471 [00:03<0epoch 15 iter 269: train loss 0.53386. lr 3.4726e-04:  56%|█████████████████████████████████████████████▏                                  | 266/471 [00:03<0epoch 15 iter 270: train loss 0.64999. lr 3.4725e-04:  56%|█████████████████████████████████████████████▏                                  | 266/471 [00:03<0epoch 15 iter 271: train loss 0.61798. lr 3.4723e-04:  56%|█████████████████████████████████████████████▏                                  | 266/471 [00:03<0epoch 15 iter 272: train loss 0.60460. lr 3.4722e-04:  56%|█████████████████████████████████████████████▏                                  | 266/471 [00:03<0epoch 15 iter 273: train loss 0.67270. lr 3.4720e-04:  56%|█████████████████████████████████████████████▏                                  | 266/471 [00:03<0epoch 15 iter 274: train loss 0.53921. lr 3.4719e-04:  56%|█████████████████████████████████████████████▏                                  | 266/471 [00:03<0epoch 15 iter 274: train loss 0.53921. lr 3.4719e-04:  58%|██████████████████████████████████████████████▋                                 | 275/471 [00:03<0epoch 15 iter 275: train loss 0.64811. lr 3.4717e-04:  58%|██████████████████████████████████████████████▋                                 | 275/471 [00:03<0epoch 15 iter 276: train loss 0.61053. lr 3.4716e-04:  58%|██████████████████████████████████████████████▋                                 | 275/471 [00:03<0epoch 15 iter 277: train loss 0.53495. lr 3.4714e-04:  58%|██████████████████████████████████████████████▋                                 | 275/471 [00:03<0epoch 15 iter 278: train loss 0.52361. lr 3.4713e-04:  58%|██████████████████████████████████████████████▋                                 | 275/471 [00:03<0epoch 15 iter 279: train loss 0.69291. lr 3.4711e-04:  58%|██████████████████████████████████████████████▋                                 | 275/471 [00:03<0epoch 15 iter 280: train loss 0.61724. lr 3.4710e-04:  58%|██████████████████████████████████████████████▋                                 | 275/471 [00:03<0epoch 15 iter 281: train loss 0.60637. lr 3.4709e-04:  58%|██████████████████████████████████████████████▋                                 | 275/471 [00:03<0epoch 15 iter 282: train loss 0.56374. lr 3.4707e-04:  58%|██████████████████████████████████████████████▋                                 | 275/471 [00:03<0epoch 15 iter 283: train loss 0.58668. lr 3.4706e-04:  58%|██████████████████████████████████████████████▋                                 | 275/471 [00:03<0epoch 15 iter 283: train loss 0.58668. lr 3.4706e-04:  60%|████████████████████████████████████████████████▏                               | 284/471 [00:03<0epoch 15 iter 284: train loss 0.50630. lr 3.4704e-04:  60%|████████████████████████████████████████████████▏                               | 284/471 [00:03<0epoch 15 iter 285: train loss 0.58992. lr 3.4703e-04:  60%|████████████████████████████████████████████████▏                               | 284/471 [00:03<0epoch 15 iter 286: train loss 0.62121. lr 3.4701e-04:  60%|████████████████████████████████████████████████▏                               | 284/471 [00:03<0epoch 15 iter 287: train loss 0.59508. lr 3.4700e-04:  60%|████████████████████████████████████████████████▏                               | 284/471 [00:03<0epoch 15 iter 288: train loss 0.54049. lr 3.4698e-04:  60%|████████████████████████████████████████████████▏                               | 284/471 [00:03<0epoch 15 iter 289: train loss 0.56101. lr 3.4697e-04:  60%|████████████████████████████████████████████████▏                               | 284/471 [00:03<0epoch 15 iter 290: train loss 0.50772. lr 3.4695e-04:  60%|████████████████████████████████████████████████▏                               | 284/471 [00:03<0epoch 15 iter 291: train loss 0.58186. lr 3.4694e-04:  60%|████████████████████████████████████████████████▏                               | 284/471 [00:03<0epoch 15 iter 292: train loss 0.58768. lr 3.4692e-04:  60%|████████████████████████████████████████████████▏                               | 284/471 [00:03<0epoch 15 iter 292: train loss 0.58768. lr 3.4692e-04:  62%|█████████████████████████████████████████████████▊                              | 293/471 [00:03<0epoch 15 iter 293: train loss 0.53852. lr 3.4691e-04:  62%|█████████████████████████████████████████████████▊                              | 293/471 [00:03<0epoch 15 iter 294: train loss 0.56660. lr 3.4689e-04:  62%|█████████████████████████████████████████████████▊                              | 293/471 [00:03<0epoch 15 iter 295: train loss 0.63043. lr 3.4688e-04:  62%|█████████████████████████████████████████████████▊                              | 293/471 [00:03<0epoch 15 iter 296: train loss 0.70186. lr 3.4686e-04:  62%|█████████████████████████████████████████████████▊                              | 293/471 [00:03<0epoch 15 iter 297: train loss 0.56832. lr 3.4685e-04:  62%|█████████████████████████████████████████████████▊                              | 293/471 [00:03<0epoch 15 iter 298: train loss 0.64317. lr 3.4683e-04:  62%|█████████████████████████████████████████████████▊                              | 293/471 [00:03<0epoch 15 iter 299: train loss 0.56714. lr 3.4682e-04:  62%|█████████████████████████████████████████████████▊                              | 293/471 [00:03<0epoch 15 iter 300: train loss 0.65821. lr 3.4680e-04:  62%|█████████████████████████████████████████████████▊                              | 293/471 [00:03<0epoch 15 iter 301: train loss 0.58953. lr 3.4679e-04:  62%|█████████████████████████████████████████████████▊                              | 293/471 [00:03<0epoch 15 iter 301: train loss 0.58953. lr 3.4679e-04:  64%|███████████████████████████████████████████████████▎                            | 302/471 [00:03<0epoch 15 iter 302: train loss 0.58401. lr 3.4677e-04:  64%|███████████████████████████████████████████████████▎                            | 302/471 [00:03<0epoch 15 iter 303: train loss 0.54466. lr 3.4676e-04:  64%|███████████████████████████████████████████████████▎                            | 302/471 [00:03<0epoch 15 iter 304: train loss 0.64167. lr 3.4674e-04:  64%|███████████████████████████████████████████████████▎                            | 302/471 [00:03<0epoch 15 iter 305: train loss 0.61165. lr 3.4673e-04:  64%|███████████████████████████████████████████████████▎                            | 302/471 [00:03<0epoch 15 iter 306: train loss 0.69507. lr 3.4671e-04:  64%|███████████████████████████████████████████████████▎                            | 302/471 [00:03<0epoch 15 iter 307: train loss 0.50882. lr 3.4670e-04:  64%|███████████████████████████████████████████████████▎                            | 302/471 [00:03<0epoch 15 iter 308: train loss 0.49464. lr 3.4669e-04:  64%|███████████████████████████████████████████████████▎                            | 302/471 [00:03<0epoch 15 iter 309: train loss 0.54284. lr 3.4667e-04:  64%|███████████████████████████████████████████████████▎                            | 302/471 [00:03<0epoch 15 iter 310: train loss 0.54950. lr 3.4666e-04:  64%|███████████████████████████████████████████████████▎                            | 302/471 [00:03<0epoch 15 iter 310: train loss 0.54950. lr 3.4666e-04:  66%|████████████████████████████████████████████████████▊                           | 311/471 [00:03<0epoch 15 iter 311: train loss 0.65720. lr 3.4664e-04:  66%|████████████████████████████████████████████████████▊                           | 311/471 [00:04<0epoch 15 iter 312: train loss 0.51647. lr 3.4663e-04:  66%|████████████████████████████████████████████████████▊                           | 311/471 [00:04<0epoch 15 iter 313: train loss 0.51884. lr 3.4661e-04:  66%|████████████████████████████████████████████████████▊                           | 311/471 [00:04<0epoch 15 iter 314: train loss 0.61273. lr 3.4660e-04:  66%|████████████████████████████████████████████████████▊                           | 311/471 [00:04<0epoch 15 iter 315: train loss 0.70145. lr 3.4658e-04:  66%|████████████████████████████████████████████████████▊                           | 311/471 [00:04<0epoch 15 iter 316: train loss 0.56128. lr 3.4657e-04:  66%|████████████████████████████████████████████████████▊                           | 311/471 [00:04<0epoch 15 iter 317: train loss 0.49380. lr 3.4655e-04:  66%|████████████████████████████████████████████████████▊                           | 311/471 [00:04<0epoch 15 iter 318: train loss 0.62488. lr 3.4654e-04:  66%|████████████████████████████████████████████████████▊                           | 311/471 [00:04<0epoch 15 iter 319: train loss 0.66248. lr 3.4652e-04:  66%|████████████████████████████████████████████████████▊                           | 311/471 [00:04<0epoch 15 iter 319: train loss 0.66248. lr 3.4652e-04:  68%|██████████████████████████████████████████████████████▎                         | 320/471 [00:04<0epoch 15 iter 320: train loss 0.54970. lr 3.4651e-04:  68%|██████████████████████████████████████████████████████▎                         | 320/471 [00:04<0epoch 15 iter 321: train loss 0.56713. lr 3.4649e-04:  68%|██████████████████████████████████████████████████████▎                         | 320/471 [00:04<0epoch 15 iter 322: train loss 0.66596. lr 3.4648e-04:  68%|██████████████████████████████████████████████████████▎                         | 320/471 [00:04<0epoch 15 iter 323: train loss 0.52755. lr 3.4646e-04:  68%|██████████████████████████████████████████████████████▎                         | 320/471 [00:04<0epoch 15 iter 324: train loss 0.61276. lr 3.4645e-04:  68%|██████████████████████████████████████████████████████▎                         | 320/471 [00:04<0epoch 15 iter 325: train loss 0.56772. lr 3.4643e-04:  68%|██████████████████████████████████████████████████████▎                         | 320/471 [00:04<0epoch 15 iter 326: train loss 0.66820. lr 3.4642e-04:  68%|██████████████████████████████████████████████████████▎                         | 320/471 [00:04<0epoch 15 iter 327: train loss 0.56582. lr 3.4640e-04:  68%|██████████████████████████████████████████████████████▎                         | 320/471 [00:04<0epoch 15 iter 328: train loss 0.67555. lr 3.4639e-04:  68%|██████████████████████████████████████████████████████▎                         | 320/471 [00:04<0epoch 15 iter 328: train loss 0.67555. lr 3.4639e-04:  70%|███████████████████████████████████████████████████████▉                        | 329/471 [00:04<0epoch 15 iter 329: train loss 0.51561. lr 3.4637e-04:  70%|███████████████████████████████████████████████████████▉                        | 329/471 [00:04<0epoch 15 iter 330: train loss 0.61429. lr 3.4636e-04:  70%|███████████████████████████████████████████████████████▉                        | 329/471 [00:04<0epoch 15 iter 331: train loss 0.65753. lr 3.4634e-04:  70%|███████████████████████████████████████████████████████▉                        | 329/471 [00:04<0epoch 15 iter 332: train loss 0.65604. lr 3.4633e-04:  70%|███████████████████████████████████████████████████████▉                        | 329/471 [00:04<0epoch 15 iter 333: train loss 0.58410. lr 3.4631e-04:  70%|███████████████████████████████████████████████████████▉                        | 329/471 [00:04<0epoch 15 iter 334: train loss 0.53828. lr 3.4630e-04:  70%|███████████████████████████████████████████████████████▉                        | 329/471 [00:04<0epoch 15 iter 335: train loss 0.61797. lr 3.4628e-04:  70%|███████████████████████████████████████████████████████▉                        | 329/471 [00:04<0epoch 15 iter 336: train loss 0.58397. lr 3.4627e-04:  70%|███████████████████████████████████████████████████████▉                        | 329/471 [00:04<0epoch 15 iter 337: train loss 0.56657. lr 3.4625e-04:  70%|███████████████████████████████████████████████████████▉                        | 329/471 [00:04<0epoch 15 iter 337: train loss 0.56657. lr 3.4625e-04:  72%|█████████████████████████████████████████████████████████▍                      | 338/471 [00:04<0epoch 15 iter 338: train loss 0.56251. lr 3.4624e-04:  72%|█████████████████████████████████████████████████████████▍                      | 338/471 [00:04<0epoch 15 iter 339: train loss 0.50268. lr 3.4622e-04:  72%|█████████████████████████████████████████████████████████▍                      | 338/471 [00:04<0epoch 15 iter 340: train loss 0.66298. lr 3.4621e-04:  72%|█████████████████████████████████████████████████████████▍                      | 338/471 [00:04<0epoch 15 iter 341: train loss 0.58923. lr 3.4619e-04:  72%|█████████████████████████████████████████████████████████▍                      | 338/471 [00:04<0epoch 15 iter 342: train loss 0.56930. lr 3.4618e-04:  72%|█████████████████████████████████████████████████████████▍                      | 338/471 [00:04<0epoch 15 iter 343: train loss 0.64668. lr 3.4616e-04:  72%|█████████████████████████████████████████████████████████▍                      | 338/471 [00:04<0epoch 15 iter 344: train loss 0.62141. lr 3.4615e-04:  72%|█████████████████████████████████████████████████████████▍                      | 338/471 [00:04<0epoch 15 iter 345: train loss 0.64034. lr 3.4613e-04:  72%|█████████████████████████████████████████████████████████▍                      | 338/471 [00:04<0epoch 15 iter 346: train loss 0.54946. lr 3.4612e-04:  72%|█████████████████████████████████████████████████████████▍                      | 338/471 [00:04<0epoch 15 iter 346: train loss 0.54946. lr 3.4612e-04:  74%|██████████████████████████████████████████████████████████▉                     | 347/471 [00:04<0epoch 15 iter 347: train loss 0.55238. lr 3.4610e-04:  74%|██████████████████████████████████████████████████████████▉                     | 347/471 [00:04<0epoch 15 iter 348: train loss 0.59747. lr 3.4609e-04:  74%|██████████████████████████████████████████████████████████▉                     | 347/471 [00:04<0epoch 15 iter 349: train loss 0.72902. lr 3.4608e-04:  74%|██████████████████████████████████████████████████████████▉                     | 347/471 [00:04<0epoch 15 iter 350: train loss 0.66919. lr 3.4606e-04:  74%|██████████████████████████████████████████████████████████▉                     | 347/471 [00:04<0epoch 15 iter 351: train loss 0.53023. lr 3.4605e-04:  74%|██████████████████████████████████████████████████████████▉                     | 347/471 [00:04<0epoch 15 iter 352: train loss 0.57763. lr 3.4603e-04:  74%|██████████████████████████████████████████████████████████▉                     | 347/471 [00:04<0epoch 15 iter 353: train loss 0.59003. lr 3.4602e-04:  74%|██████████████████████████████████████████████████████████▉                     | 347/471 [00:04<0epoch 15 iter 354: train loss 0.57618. lr 3.4600e-04:  74%|██████████████████████████████████████████████████████████▉                     | 347/471 [00:04<0epoch 15 iter 355: train loss 0.65207. lr 3.4599e-04:  74%|██████████████████████████████████████████████████████████▉                     | 347/471 [00:04<0epoch 15 iter 355: train loss 0.65207. lr 3.4599e-04:  76%|████████████████████████████████████████████████████████████▍                   | 356/471 [00:04<0epoch 15 iter 356: train loss 0.57203. lr 3.4597e-04:  76%|████████████████████████████████████████████████████████████▍                   | 356/471 [00:04<0epoch 15 iter 357: train loss 0.67266. lr 3.4596e-04:  76%|████████████████████████████████████████████████████████████▍                   | 356/471 [00:04<0epoch 15 iter 358: train loss 0.64407. lr 3.4594e-04:  76%|████████████████████████████████████████████████████████████▍                   | 356/471 [00:04<0epoch 15 iter 359: train loss 0.85688. lr 3.4593e-04:  76%|████████████████████████████████████████████████████████████▍                   | 356/471 [00:04<0epoch 15 iter 360: train loss 0.54855. lr 3.4591e-04:  76%|████████████████████████████████████████████████████████████▍                   | 356/471 [00:04<0epoch 15 iter 361: train loss 0.61320. lr 3.4590e-04:  76%|████████████████████████████████████████████████████████████▍                   | 356/471 [00:04<0epoch 15 iter 362: train loss 0.56525. lr 3.4588e-04:  76%|████████████████████████████████████████████████████████████▍                   | 356/471 [00:04<0epoch 15 iter 363: train loss 0.75345. lr 3.4587e-04:  76%|████████████████████████████████████████████████████████████▍                   | 356/471 [00:04<0epoch 15 iter 364: train loss 0.59523. lr 3.4585e-04:  76%|████████████████████████████████████████████████████████████▍                   | 356/471 [00:04<0epoch 15 iter 364: train loss 0.59523. lr 3.4585e-04:  77%|█████████████████████████████████████████████████████████████▉                  | 365/471 [00:04<0epoch 15 iter 365: train loss 0.58964. lr 3.4584e-04:  77%|█████████████████████████████████████████████████████████████▉                  | 365/471 [00:04<0epoch 15 iter 366: train loss 0.65603. lr 3.4582e-04:  77%|█████████████████████████████████████████████████████████████▉                  | 365/471 [00:04<0epoch 15 iter 367: train loss 0.53220. lr 3.4581e-04:  77%|█████████████████████████████████████████████████████████████▉                  | 365/471 [00:04<0epoch 15 iter 368: train loss 0.56916. lr 3.4579e-04:  77%|█████████████████████████████████████████████████████████████▉                  | 365/471 [00:04<0epoch 15 iter 369: train loss 0.52994. lr 3.4578e-04:  77%|█████████████████████████████████████████████████████████████▉                  | 365/471 [00:04<0epoch 15 iter 370: train loss 0.58308. lr 3.4576e-04:  77%|█████████████████████████████████████████████████████████████▉                  | 365/471 [00:04<0epoch 15 iter 371: train loss 0.51815. lr 3.4575e-04:  77%|█████████████████████████████████████████████████████████████▉                  | 365/471 [00:04<0epoch 15 iter 372: train loss 0.55475. lr 3.4573e-04:  77%|█████████████████████████████████████████████████████████████▉                  | 365/471 [00:04<0epoch 15 iter 373: train loss 0.57479. lr 3.4572e-04:  77%|█████████████████████████████████████████████████████████████▉                  | 365/471 [00:04<0epoch 15 iter 373: train loss 0.57479. lr 3.4572e-04:  79%|███████████████████████████████████████████████████████████████▌                | 374/471 [00:04<0epoch 15 iter 374: train loss 0.57856. lr 3.4570e-04:  79%|███████████████████████████████████████████████████████████████▌                | 374/471 [00:04<0epoch 15 iter 375: train loss 0.51782. lr 3.4569e-04:  79%|███████████████████████████████████████████████████████████████▌                | 374/471 [00:04<0epoch 15 iter 376: train loss 0.63050. lr 3.4567e-04:  79%|███████████████████████████████████████████████████████████████▌                | 374/471 [00:04<0epoch 15 iter 377: train loss 0.50425. lr 3.4566e-04:  79%|███████████████████████████████████████████████████████████████▌                | 374/471 [00:04<0epoch 15 iter 378: train loss 0.49655. lr 3.4564e-04:  79%|███████████████████████████████████████████████████████████████▌                | 374/471 [00:04<0epoch 15 iter 379: train loss 0.61085. lr 3.4563e-04:  79%|███████████████████████████████████████████████████████████████▌                | 374/471 [00:04<0epoch 15 iter 380: train loss 0.56293. lr 3.4561e-04:  79%|███████████████████████████████████████████████████████████████▌                | 374/471 [00:04<0epoch 15 iter 381: train loss 0.52103. lr 3.4560e-04:  79%|███████████████████████████████████████████████████████████████▌                | 374/471 [00:04<0epoch 15 iter 382: train loss 0.53606. lr 3.4558e-04:  79%|███████████████████████████████████████████████████████████████▌                | 374/471 [00:04<0epoch 15 iter 382: train loss 0.53606. lr 3.4558e-04:  81%|█████████████████████████████████████████████████████████████████               | 383/471 [00:04<0epoch 15 iter 383: train loss 0.67211. lr 3.4557e-04:  81%|█████████████████████████████████████████████████████████████████               | 383/471 [00:04<0epoch 15 iter 384: train loss 0.63906. lr 3.4555e-04:  81%|█████████████████████████████████████████████████████████████████               | 383/471 [00:04<0epoch 15 iter 385: train loss 0.59431. lr 3.4554e-04:  81%|█████████████████████████████████████████████████████████████████               | 383/471 [00:04<0epoch 15 iter 386: train loss 0.59876. lr 3.4552e-04:  81%|█████████████████████████████████████████████████████████████████               | 383/471 [00:04<0epoch 15 iter 387: train loss 0.60002. lr 3.4551e-04:  81%|█████████████████████████████████████████████████████████████████               | 383/471 [00:04<0epoch 15 iter 388: train loss 0.72304. lr 3.4549e-04:  81%|█████████████████████████████████████████████████████████████████               | 383/471 [00:04<0epoch 15 iter 389: train loss 0.62069. lr 3.4548e-04:  81%|█████████████████████████████████████████████████████████████████               | 383/471 [00:04<0epoch 15 iter 390: train loss 0.59826. lr 3.4546e-04:  81%|█████████████████████████████████████████████████████████████████               | 383/471 [00:04<0epoch 15 iter 391: train loss 0.60589. lr 3.4545e-04:  81%|█████████████████████████████████████████████████████████████████               | 383/471 [00:05<0epoch 15 iter 391: train loss 0.60589. lr 3.4545e-04:  83%|██████████████████████████████████████████████████████████████████▌             | 392/471 [00:05<0epoch 15 iter 392: train loss 0.64181. lr 3.4543e-04:  83%|██████████████████████████████████████████████████████████████████▌             | 392/471 [00:05<0epoch 15 iter 393: train loss 0.56011. lr 3.4542e-04:  83%|██████████████████████████████████████████████████████████████████▌             | 392/471 [00:05<0epoch 15 iter 394: train loss 0.66939. lr 3.4540e-04:  83%|██████████████████████████████████████████████████████████████████▌             | 392/471 [00:05<0epoch 15 iter 395: train loss 0.57805. lr 3.4539e-04:  83%|██████████████████████████████████████████████████████████████████▌             | 392/471 [00:05<0epoch 15 iter 396: train loss 0.59689. lr 3.4537e-04:  83%|██████████████████████████████████████████████████████████████████▌             | 392/471 [00:05<0epoch 15 iter 397: train loss 0.66590. lr 3.4536e-04:  83%|██████████████████████████████████████████████████████████████████▌             | 392/471 [00:05<0epoch 15 iter 398: train loss 0.53958. lr 3.4534e-04:  83%|██████████████████████████████████████████████████████████████████▌             | 392/471 [00:05<0epoch 15 iter 399: train loss 0.58359. lr 3.4533e-04:  83%|██████████████████████████████████████████████████████████████████▌             | 392/471 [00:05<0epoch 15 iter 400: train loss 0.63611. lr 3.4531e-04:  83%|██████████████████████████████████████████████████████████████████▌             | 392/471 [00:05<0epoch 15 iter 400: train loss 0.63611. lr 3.4531e-04:  85%|████████████████████████████████████████████████████████████████████            | 401/471 [00:05<0epoch 15 iter 401: train loss 0.58001. lr 3.4530e-04:  85%|████████████████████████████████████████████████████████████████████            | 401/471 [00:05<0epoch 15 iter 402: train loss 0.61071. lr 3.4528e-04:  85%|████████████████████████████████████████████████████████████████████            | 401/471 [00:05<0epoch 15 iter 403: train loss 0.56367. lr 3.4527e-04:  85%|████████████████████████████████████████████████████████████████████            | 401/471 [00:05<0epoch 15 iter 404: train loss 0.59204. lr 3.4525e-04:  85%|████████████████████████████████████████████████████████████████████            | 401/471 [00:05<0epoch 15 iter 405: train loss 0.59055. lr 3.4524e-04:  85%|████████████████████████████████████████████████████████████████████            | 401/471 [00:05<0step_train_loss: 0.5720690488815308 train_step: 7000, learning_rate: 0.00034522229169539934
epoch 15 iter 406: train loss 0.57207. lr 3.4522e-04:  85%|████████████████████████████████████████████████████████████████████            | 401/471 [00:05<0epoch 15 iter 407: train loss 0.56010. lr 3.4521e-04:  85%|████████████████████████████████████████████████████████████████████            | 401/471 [00:05<0epoch 15 iter 408: train loss 0.68442. lr 3.4519e-04:  85%|████████████████████████████████████████████████████████████████████            | 401/471 [00:05<0epoch 15 iter 409: train loss 0.49216. lr 3.4518e-04:  85%|████████████████████████████████████████████████████████████████████            | 401/471 [00:05<0epoch 15 iter 409: train loss 0.49216. lr 3.4518e-04:  87%|█████████████████████████████████████████████████████████████████████▋          | 410/471 [00:05<0epoch 15 iter 410: train loss 0.61934. lr 3.4516e-04:  87%|█████████████████████████████████████████████████████████████████████▋          | 410/471 [00:05<0epoch 15 iter 411: train loss 0.66969. lr 3.4515e-04:  87%|█████████████████████████████████████████████████████████████████████▋          | 410/471 [00:05<0epoch 15 iter 412: train loss 0.67916. lr 3.4513e-04:  87%|█████████████████████████████████████████████████████████████████████▋          | 410/471 [00:05<0epoch 15 iter 413: train loss 0.64952. lr 3.4512e-04:  87%|█████████████████████████████████████████████████████████████████████▋          | 410/471 [00:05<0epoch 15 iter 414: train loss 0.64089. lr 3.4510e-04:  87%|█████████████████████████████████████████████████████████████████████▋          | 410/471 [00:05<0epoch 15 iter 415: train loss 0.60301. lr 3.4509e-04:  87%|█████████████████████████████████████████████████████████████████████▋          | 410/471 [00:05<0epoch 15 iter 416: train loss 0.58672. lr 3.4507e-04:  87%|█████████████████████████████████████████████████████████████████████▋          | 410/471 [00:05<0epoch 15 iter 417: train loss 0.54585. lr 3.4506e-04:  87%|█████████████████████████████████████████████████████████████████████▋          | 410/471 [00:05<0epoch 15 iter 418: train loss 0.57489. lr 3.4504e-04:  87%|█████████████████████████████████████████████████████████████████████▋          | 410/471 [00:05<0epoch 15 iter 418: train loss 0.57489. lr 3.4504e-04:  89%|███████████████████████████████████████████████████████████████████████▏        | 419/471 [00:05<0epoch 15 iter 419: train loss 0.61994. lr 3.4503e-04:  89%|███████████████████████████████████████████████████████████████████████▏        | 419/471 [00:05<0epoch 15 iter 420: train loss 0.49927. lr 3.4501e-04:  89%|███████████████████████████████████████████████████████████████████████▏        | 419/471 [00:05<0epoch 15 iter 421: train loss 0.65691. lr 3.4500e-04:  89%|███████████████████████████████████████████████████████████████████████▏        | 419/471 [00:05<0epoch 15 iter 422: train loss 0.53166. lr 3.4498e-04:  89%|███████████████████████████████████████████████████████████████████████▏        | 419/471 [00:05<0epoch 15 iter 423: train loss 0.61217. lr 3.4497e-04:  89%|███████████████████████████████████████████████████████████████████████▏        | 419/471 [00:05<0epoch 15 iter 424: train loss 0.61788. lr 3.4495e-04:  89%|███████████████████████████████████████████████████████████████████████▏        | 419/471 [00:05<0epoch 15 iter 425: train loss 0.68124. lr 3.4494e-04:  89%|███████████████████████████████████████████████████████████████████████▏        | 419/471 [00:05<0epoch 15 iter 426: train loss 0.57220. lr 3.4492e-04:  89%|███████████████████████████████████████████████████████████████████████▏        | 419/471 [00:05<0epoch 15 iter 427: train loss 0.63179. lr 3.4491e-04:  89%|███████████████████████████████████████████████████████████████████████▏        | 419/471 [00:05<0epoch 15 iter 427: train loss 0.63179. lr 3.4491e-04:  91%|████████████████████████████████████████████████████████████████████████▋       | 428/471 [00:05<0epoch 15 iter 428: train loss 0.64268. lr 3.4489e-04:  91%|████████████████████████████████████████████████████████████████████████▋       | 428/471 [00:05<0epoch 15 iter 429: train loss 0.60171. lr 3.4488e-04:  91%|████████████████████████████████████████████████████████████████████████▋       | 428/471 [00:05<0epoch 15 iter 430: train loss 0.65463. lr 3.4486e-04:  91%|████████████████████████████████████████████████████████████████████████▋       | 428/471 [00:05<0epoch 15 iter 431: train loss 0.56413. lr 3.4485e-04:  91%|████████████████████████████████████████████████████████████████████████▋       | 428/471 [00:05<0epoch 15 iter 432: train loss 0.48023. lr 3.4483e-04:  91%|████████████████████████████████████████████████████████████████████████▋       | 428/471 [00:05<0epoch 15 iter 433: train loss 0.53614. lr 3.4482e-04:  91%|████████████████████████████████████████████████████████████████████████▋       | 428/471 [00:05<0epoch 15 iter 434: train loss 0.65269. lr 3.4480e-04:  91%|████████████████████████████████████████████████████████████████████████▋       | 428/471 [00:05<0epoch 15 iter 435: train loss 0.53980. lr 3.4479e-04:  91%|████████████████████████████████████████████████████████████████████████▋       | 428/471 [00:05<0epoch 15 iter 436: train loss 0.62655. lr 3.4477e-04:  91%|████████████████████████████████████████████████████████████████████████▋       | 428/471 [00:05<0epoch 15 iter 436: train loss 0.62655. lr 3.4477e-04:  93%|██████████████████████████████████████████████████████████████████████████▏     | 437/471 [00:05<0epoch 15 iter 437: train loss 0.52449. lr 3.4476e-04:  93%|██████████████████████████████████████████████████████████████████████████▏     | 437/471 [00:05<0epoch 15 iter 438: train loss 0.58012. lr 3.4474e-04:  93%|██████████████████████████████████████████████████████████████████████████▏     | 437/471 [00:05<0epoch 15 iter 439: train loss 0.63427. lr 3.4473e-04:  93%|██████████████████████████████████████████████████████████████████████████▏     | 437/471 [00:05<0epoch 15 iter 440: train loss 0.57760. lr 3.4471e-04:  93%|██████████████████████████████████████████████████████████████████████████▏     | 437/471 [00:05<0epoch 15 iter 441: train loss 0.53752. lr 3.4470e-04:  93%|██████████████████████████████████████████████████████████████████████████▏     | 437/471 [00:05<0epoch 15 iter 442: train loss 0.73550. lr 3.4468e-04:  93%|██████████████████████████████████████████████████████████████████████████▏     | 437/471 [00:05<0epoch 15 iter 443: train loss 0.59531. lr 3.4467e-04:  93%|██████████████████████████████████████████████████████████████████████████▏     | 437/471 [00:05<0epoch 15 iter 444: train loss 0.62753. lr 3.4465e-04:  93%|██████████████████████████████████████████████████████████████████████████▏     | 437/471 [00:05<0epoch 15 iter 445: train loss 0.49042. lr 3.4464e-04:  93%|██████████████████████████████████████████████████████████████████████████▏     | 437/471 [00:05<0epoch 15 iter 445: train loss 0.49042. lr 3.4464e-04:  95%|███████████████████████████████████████████████████████████████████████████▊    | 446/471 [00:05<0epoch 15 iter 446: train loss 0.49811. lr 3.4462e-04:  95%|███████████████████████████████████████████████████████████████████████████▊    | 446/471 [00:05<0epoch 15 iter 447: train loss 0.51659. lr 3.4461e-04:  95%|███████████████████████████████████████████████████████████████████████████▊    | 446/471 [00:05<0epoch 15 iter 448: train loss 0.61508. lr 3.4459e-04:  95%|███████████████████████████████████████████████████████████████████████████▊    | 446/471 [00:05<0epoch 15 iter 449: train loss 0.62494. lr 3.4458e-04:  95%|███████████████████████████████████████████████████████████████████████████▊    | 446/471 [00:05<0epoch 15 iter 450: train loss 0.60799. lr 3.4456e-04:  95%|███████████████████████████████████████████████████████████████████████████▊    | 446/471 [00:05<0epoch 15 iter 451: train loss 0.60161. lr 3.4455e-04:  95%|███████████████████████████████████████████████████████████████████████████▊    | 446/471 [00:05<0epoch 15 iter 452: train loss 0.59322. lr 3.4453e-04:  95%|███████████████████████████████████████████████████████████████████████████▊    | 446/471 [00:05<0epoch 15 iter 453: train loss 0.55749. lr 3.4451e-04:  95%|███████████████████████████████████████████████████████████████████████████▊    | 446/471 [00:05<0epoch 15 iter 454: train loss 0.69413. lr 3.4450e-04:  95%|███████████████████████████████████████████████████████████████████████████▊    | 446/471 [00:05<0epoch 15 iter 454: train loss 0.69413. lr 3.4450e-04:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 455/471 [00:05<0epoch 15 iter 455: train loss 0.50896. lr 3.4448e-04:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 455/471 [00:05<0epoch 15 iter 456: train loss 0.58572. lr 3.4447e-04:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 455/471 [00:05<0epoch 15 iter 457: train loss 0.64198. lr 3.4445e-04:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 455/471 [00:05<0epoch 15 iter 458: train loss 0.57530. lr 3.4444e-04:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 455/471 [00:05<0epoch 15 iter 459: train loss 0.61699. lr 3.4442e-04:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 455/471 [00:05<0epoch 15 iter 460: train loss 0.60080. lr 3.4441e-04:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 455/471 [00:05<0epoch 15 iter 461: train loss 0.64872. lr 3.4439e-04:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 455/471 [00:05<0epoch 15 iter 462: train loss 0.67279. lr 3.4438e-04:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 455/471 [00:05<0epoch 15 iter 463: train loss 0.54557. lr 3.4436e-04:  97%|█████████████████████████████████████████████████████████████████████████████▎  | 455/471 [00:05<0epoch 15 iter 463: train loss 0.54557. lr 3.4436e-04:  99%|██████████████████████████████████████████████████████████████████████████████▊ | 464/471 [00:05<0epoch 15 iter 464: train loss 0.73457. lr 3.4435e-04:  99%|██████████████████████████████████████████████████████████████████████████████▊ | 464/471 [00:05<0epoch 15 iter 465: train loss 0.57391. lr 3.4433e-04:  99%|██████████████████████████████████████████████████████████████████████████████▊ | 464/471 [00:05<0epoch 15 iter 466: train loss 0.51978. lr 3.4432e-04:  99%|██████████████████████████████████████████████████████████████████████████████▊ | 464/471 [00:05<0epoch 15 iter 467: train loss 0.52681. lr 3.4430e-04:  99%|██████████████████████████████████████████████████████████████████████████████▊ | 464/471 [00:05<0epoch 15 iter 468: train loss 0.58222. lr 3.4429e-04:  99%|██████████████████████████████████████████████████████████████████████████████▊ | 464/471 [00:05<0epoch 15 iter 469: train loss 0.56269. lr 3.4427e-04:  99%|██████████████████████████████████████████████████████████████████████████████▊ | 464/471 [00:05<0epoch 15 iter 470: train loss 0.49688. lr 3.4427e-04:  99%|██████████████████████████████████████████████████████████████████████████████▊ | 464/471 [00:05<0epoch 15 iter 470: train loss 0.49688. lr 3.4427e-04: 100%|████████████████████████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 74.52it/s]
test loss: %f 0.4650321009586442
step_train_loss: 0.6867283582687378 train_step: 7500, learning_rate: 0.0003375128626301622██████████████████████████▋     | 431/471 [00:07<00:00, 69.12it/s]
epoch 16 iter 470: train loss 0.78761. lr 3.3697e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 58.00it/s] 
test loss: %f 0.45439293024674904
step_train_loss: 0.5449137091636658 train_step: 8000, learning_rate: 0.00032939478482442577█████████████████████████████▎ | 458/471 [00:06<00:00, 75.00it/s]
epoch 17 iter 470: train loss 0.69165. lr 3.2930e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 67.89it/s] 
test loss: %f 0.44794837596281517
epoch 18 iter 470: train loss 0.53902. lr 3.2130e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 73.49it/s]
test loss: %f 0.43613758177127476
step_train_loss: 0.5309847593307495 train_step: 8500, learning_rate: 0.0003209014219291752                                 | 16/471 [00:00<00:08, 56.01it/s]
epoch 19 iter 470: train loss 0.61026. lr 3.1298e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:06<00:00, 75.07it/s] 
test loss: %f 0.44204229228901415
step_train_loss: 0.5967511534690857 train_step: 9000, learning_rate: 0.0003120399314345408                                 | 51/471 [00:00<00:05, 72.75it/s]
epoch 20 iter 470: train loss 0.50785. lr 3.0436e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 58.23it/s] 
test loss: %f 0.4412022182401621
step_train_loss: 0.5396515130996704 train_step: 9500, learning_rate: 0.0003028454904362906                                 | 75/471 [00:01<00:05, 73.91it/s]
epoch 21 iter 470: train loss 0.40762. lr 2.9546e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 66.82it/s] 
test loss: %f 0.42670621568301936
step_train_loss: 0.526421308517456 train_step: 10000, learning_rate: 0.00029334542217285974                               | 107/471 [00:02<00:06, 54.19it/s]
epoch 22 iter 470: train loss 0.63241. lr 2.8632e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 57.23it/s] 
test loss: %f 0.425328754029184
step_train_loss: 0.5002496242523193 train_step: 10500, learning_rate: 0.0002835679581191534                               | 134/471 [00:02<00:05, 57.81it/s]
epoch 23 iter 470: train loss 0.69304. lr 2.7694e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 52.97it/s] 
test loss: %f 0.4179720529970133
step_train_loss: 0.5695288181304932 train_step: 11000, learning_rate: 0.00027354215409071083                              | 163/471 [00:02<00:05, 56.98it/s]
epoch 24 iter 470: train loss 0.49025. lr 2.6736e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 55.72it/s] 
test loss: %f 0.4184058499786089
step_train_loss: 0.5142491459846497 train_step: 11500, learning_rate: 0.0002632978038981643                               | 193/471 [00:03<00:05, 50.84it/s]
epoch 25 iter 470: train loss 0.55096. lr 2.5761e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 63.07it/s] 
test loss: %f 0.4042757524634307
step_train_loss: 0.5961034297943115 train_step: 12000, learning_rate: 0.00025286536480778875                              | 220/471 [00:04<00:03, 65.75it/s]
epoch 26 iter 470: train loss 0.48165. lr 2.4770e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 60.91it/s] 
test loss: %f 0.396879143872351
step_train_loss: 0.4806152880191803 train_step: 12500, learning_rate: 0.00024227579707685842▎                             | 249/471 [00:04<00:03, 56.75it/s]
epoch 27 iter 470: train loss 0.45091. lr 2.3767e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 53.24it/s] 
test loss: %f 0.39719536844289527
step_train_loss: 0.5346136093139648 train_step: 13000, learning_rate: 0.00023156059748224048████▋                         | 282/471 [00:04<00:03, 55.61it/s]
epoch 28 iter 470: train loss 0.58430. lr 2.2753e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 55.96it/s] 
test loss: %f 0.39238707580656373
step_train_loss: 0.5705851912498474 train_step: 13500, learning_rate: 0.00022075163747922814████████▏                     | 308/471 [00:04<00:02, 70.47it/s]
epoch 29 iter 470: train loss 0.65130. lr 2.1733e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 64.28it/s] 
test loss: %f 0.38887768533994566
step_train_loss: 0.4047428071498871 train_step: 14000, learning_rate: 0.0002098810097326676█████████████                  | 337/471 [00:05<00:02, 66.69it/s]
epoch 30 iter 470: train loss 0.55289. lr 2.0708e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 55.77it/s] 
test loss: %f 0.38226615370444533
step_train_loss: 0.5474855899810791 train_step: 14500, learning_rate: 0.00019898098951014217████████████████▎             | 369/471 [00:06<00:01, 53.37it/s]
epoch 31 iter 470: train loss 0.43250. lr 1.9681e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:09<00:00, 51.83it/s] 
test loss: %f 0.38069908742634756
step_train_loss: 0.5622983574867249 train_step: 15000, learning_rate: 0.00018808399750224082███████████████████▋          | 394/471 [00:06<00:01, 57.38it/s]
epoch 32 iter 470: train loss 0.45276. lr 1.8655e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 56.00it/s] 
test loss: %f 0.38375127877829207
step_train_loss: 0.5654767155647278 train_step: 15500, learning_rate: 0.00017722244536835132███████████████████████▋      | 424/471 [00:06<00:00, 70.66it/s]
epoch 33 iter 470: train loss 0.53010. lr 1.7632e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 61.27it/s] 
test loss: %f 0.37219614127896866
step_train_loss: 0.5332044959068298 train_step: 16000, learning_rate: 0.00016642858140601384███████████████████████████▉  | 456/471 [00:07<00:00, 66.50it/s]
epoch 34 iter 470: train loss 0.54397. lr 1.6616e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 60.23it/s] 
test loss: %f 0.3667275275824205
epoch 35 iter 470: train loss 0.27856. lr 1.5609e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 52.72it/s]
test loss: %f 0.3626482278670905
step_train_loss: 0.52492356300354 train_step: 16500, learning_rate: 0.00015574574962806868                                 | 10/471 [00:00<00:09, 51.13it/s]
epoch 36 iter 470: train loss 0.39369. lr 1.4613e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:09<00:00, 47.96it/s] 
test loss: %f 0.3547415058567839
step_train_loss: 0.4959792494773865 train_step: 17000, learning_rate: 0.00014518303799595624                               | 43/471 [00:00<00:09, 45.92it/s]
epoch 37 iter 470: train loss 0.37767. lr 1.3631e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 58.91it/s] 
test loss: %f 0.3512413248700916
step_train_loss: 0.4604146182537079 train_step: 17500, learning_rate: 0.00013478322620046382                               | 67/471 [00:01<00:06, 63.62it/s]
epoch 38 iter 470: train loss 0.47351. lr 1.2666e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 60.47it/s] 
test loss: %f 0.3445872450774571
step_train_loss: 0.5056092143058777 train_step: 18000, learning_rate: 0.00012457719252615665                               | 97/471 [00:01<00:06, 56.91it/s]
epoch 39 iter 470: train loss 0.55449. lr 1.1721e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 55.40it/s] 
test loss: %f 0.3374015624230763
step_train_loss: 0.3988872170448303 train_step: 18500, learning_rate: 0.00011459529437436298                              | 126/471 [00:02<00:06, 54.60it/s]
epoch 40 iter 470: train loss 0.55767. lr 1.0797e-04: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 53.75it/s] 
test loss: %f 0.3377185677582363
step_train_loss: 0.4704383909702301 train_step: 19000, learning_rate: 0.00010486722069541138                              | 157/471 [00:02<00:04, 68.93it/s]
epoch 41 iter 470: train loss 0.41204. lr 9.8980e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:07<00:00, 60.40it/s] 
test loss: %f 0.3364850434492219
step_train_loss: 0.5009388327598572 train_step: 19500, learning_rate: 9.542185356639169e-05                               | 188/471 [00:03<00:04, 65.74it/s]
epoch 42 iter 470: train loss 0.48490. lr 9.0252e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:08<00:00, 57.36it/s] 
test loss: %f 0.3324133680676514
step_train_loss: 0.5782855749130249 train_step: 20000, learning_rate: 8.628723794944675e-05                               | 218/471 [00:06<00:08, 31.21it/s]
epoch 43 iter 470: train loss 0.44681. lr 8.1814e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:14<00:00, 31.43it/s] 
test loss: %f 0.3290129160543658
step_train_loss: 0.4540121257305145 train_step: 20500, learning_rate: 7.749054490781146e-05▎                              | 242/471 [00:05<00:04, 48.34it/s]
epoch 44 iter 470: train loss 0.60428. lr 7.3688e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:10<00:00, 43.82it/s] 
test loss: %f 0.32280023086745785
step_train_loss: 0.41797584295272827 train_step: 21000, learning_rate: 6.905793770068935e-05███▋                          | 274/471 [00:06<00:05, 38.30it/s]
epoch 45 iter 470: train loss 0.49754. lr 6.5895e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:10<00:00, 44.02it/s] 
test loss: %f 0.32329884790024666
step_train_loss: 0.43247348070144653 train_step: 21500, learning_rate: 6.1014451666565716e-05██████▏                      | 300/471 [00:06<00:03, 52.25it/s]
epoch 46 iter 470: train loss 0.45057. lr 5.8455e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:10<00:00, 45.10it/s] 
test loss: %f 0.3253051140960657
step_train_loss: 0.4594497084617615 train_step: 22000, learning_rate: 5.33839699274308e-05█████████████▋                  | 334/471 [00:10<00:04, 31.09it/s]
epoch 47 iter 470: train loss 0.35097. lr 5.1389e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:14<00:00, 33.54it/s] 
test loss: %f 0.3185735985917865
step_train_loss: 0.39319685101509094 train_step: 22500, learning_rate: 4.6189190088156364e-05██████████████▎              | 361/471 [00:08<00:03, 31.98it/s]
epoch 48 iter 470: train loss 0.64527. lr 4.4714e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:12<00:00, 38.20it/s] 
test loss: %f 0.31927567945336394
step_train_loss: 0.5159780979156494 train_step: 23000, learning_rate: 4e-05████████████████████████████████████▎          | 391/471 [00:11<00:01, 56.52it/s]
epoch 49 iter 470: train loss 0.41308. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:13<00:00, 36.06it/s] 
test loss: %f 0.3179817314980165
step_train_loss: 0.4371800422668457 train_step: 23500, learning_rate: 4e-05████████████████████████████████████████▎      | 421/471 [00:18<00:02, 23.08it/s]
epoch 50 iter 470: train loss 0.70309. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:21<00:00, 22.34it/s] 
test loss: %f 0.3145685541742253
step_train_loss: 0.4727865159511566 train_step: 24000, learning_rate: 4e-05███████████████████████████████████████████▊   | 447/471 [00:11<00:00, 47.21it/s]
epoch 51 iter 470: train loss 0.40416. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:12<00:00, 38.04it/s] 
test loss: %f 0.3152920210136558
epoch 52 iter 470: train loss 0.45158. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:21<00:00, 22.34it/s]
test loss: %f 0.31110223677923093
step_train_loss: 0.39746183156967163 train_step: 24500, learning_rate: 4e-05                                                | 7/471 [00:00<00:14, 33.05it/s]
epoch 53 iter 470: train loss 0.56003. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:16<00:00, 29.03it/s] 
test loss: %f 0.3101659923229577
step_train_loss: 0.5201754570007324 train_step: 25000, learning_rate: 4e-05                                                | 37/471 [00:01<00:19, 22.69it/s]
epoch 54 iter 470: train loss 0.52395. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:17<00:00, 26.58it/s] 
test loss: %f 0.31369326446416246
step_train_loss: 0.4700532555580139 train_step: 25500, learning_rate: 4e-05                                                | 66/471 [00:02<00:12, 32.15it/s]
epoch 55 iter 470: train loss 0.46441. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:17<00:00, 26.41it/s] 
test loss: %f 0.3089966973606146
step_train_loss: 0.47273874282836914 train_step: 26000, learning_rate: 4e-05                                               | 93/471 [00:03<00:12, 31.04it/s]
epoch 56 iter 470: train loss 0.56317. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:15<00:00, 30.48it/s] 
test loss: %f 0.3115996591887384
step_train_loss: 0.44212785363197327 train_step: 26500, learning_rate: 4e-05                                              | 124/471 [00:04<00:11, 31.36it/s]
epoch 57 iter 470: train loss 0.44057. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:17<00:00, 27.64it/s] 
test loss: %f 0.3101090577975759
step_train_loss: 0.48824381828308105 train_step: 27000, learning_rate: 4e-05███▎                                          | 152/471 [00:06<00:11, 26.68it/s]
epoch 58 iter 470: train loss 0.48068. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:17<00:00, 26.62it/s] 
test loss: %f 0.30798913847725345
step_train_loss: 0.5131264328956604 train_step: 27500, learning_rate: 4e-05███████▉                                       | 179/471 [00:06<00:06, 45.45it/s]
epoch 59 iter 470: train loss 0.48658. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:14<00:00, 33.18it/s] 
test loss: %f 0.3110398495534681
step_train_loss: 0.3875272572040558 train_step: 28000, learning_rate: 4e-05████████████▏                                  | 211/471 [00:07<00:11, 21.98it/s]
epoch 60 iter 470: train loss 0.31192. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 471/471 [00:20<00:00, 23.54it/s] 
test loss: %f 0.3075902574467209
epoch_valid_loss: 0.3075902574467209, epoch_train_loss: 0.4698054624717453, epoch: 60
Saving at epoch 60: ./cond_gpt/weights/None_simplesplit_2layer_2head_16embd_32bs.pt
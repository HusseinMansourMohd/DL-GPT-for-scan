
Microsoft Windows [Version 10.0.22631.3374]
(c) Microsoft Corporation. All rights reserved.

(csce) C:\Users\hussein\Desktop\DL-GPT-for-scan>python main.py --task train --n_layer 10 --n_head 16 --n_embd 256 --max_epochs 60 --batch_size 128  
GPU is enabled.
The file './tokenizer/simple_vocab.json' exists. Loading tokenizer.
{'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, 'I_TURN_RIGHT': 4, 'I_JUMP': 5, 'I_WALK': 6, 'I_TURN_LEFT': 7, 'I_RUN': 8, 'I_LOOK': 9, 'jump': 10, 'opposite': 11, 'right': 12, 'twice': 13, 'and': 14, 'turn': 15, 'thrice': 16, 'run': 17, 'left': 18, 'after': 19, 'walk': 20, 'around': 21, 'look': 22}
train dataset size: 15055
val dataset size: 1673
loading model
total params: 7922688
epoch 1 iter 117: train loss 0.56594. lr 3.9979e-04: 100%|████████████████████████████████████████████████████████████████| 118/118 [00:33<00:00,  3.52it/s]
test loss: %f 0.5425104605300086
epoch 2 iter 117: train loss 0.37043. lr 3.9905e-04: 100%|████████████████████████████████████████████████████████████████| 118/118 [00:35<00:00,  3.31it/s]
test loss: %f 0.3299126774072647
epoch 3 iter 117: train loss 0.21628. lr 3.9779e-04: 100%|████████████████████████████████████████████████████████████████| 118/118 [00:39<00:00,  2.95it/s]
test loss: %f 0.18083838799170085
epoch 4 iter 117: train loss 0.17618. lr 3.9601e-04: 100%|████████████████████████████████████████████████████████████████| 118/118 [00:38<00:00,  3.07it/s]
test loss: %f 0.131029911339283
step_train_loss: 0.18537884950637817 train_step: 500, learning_rate: 0.00039548715990376116                                | 28/118 [00:09<00:24,  3.63it/s]
epoch 5 iter 117: train loss 0.12436. lr 3.9371e-04: 100%|████████████████████████████████████████████████████████████████| 118/118 [00:37<00:00,  3.17it/s]
test loss: %f 0.11158120312861033
epoch 6 iter 117: train loss 0.11456. lr 3.9090e-04: 100%|████████████████████████████████████████████████████████████████| 118/118 [00:26<00:00,  4.53it/s]
test loss: %f 0.05059949840818133
epoch 7 iter 117: train loss 0.08197. lr 3.8758e-04: 100%|████████████████████████████████████████████████████████████████| 118/118 [00:37<00:00,  3.13it/s]
test loss: %f 0.055509050243667195
epoch 8 iter 117: train loss 0.07159. lr 3.8377e-04: 100%|████████████████████████████████████████████████████████████████| 118/118 [00:37<00:00,  3.11it/s]
test loss: %f 0.06651606570397105
step_train_loss: 0.0722178965806961 train_step: 1000, learning_rate: 0.0003817531081522013                                 | 56/118 [00:18<00:22,  2.72it/s]
epoch 9 iter 117: train loss 0.07376. lr 3.7948e-04: 100%|████████████████████████████████████████████████████████████████| 118/118 [00:41<00:00,  2.86it/s] 
test loss: %f 0.036929057245807986
epoch 10 iter 117: train loss 0.04131. lr 3.7471e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:39<00:00,  2.98it/s]
test loss: %f 0.031009691833917583
epoch 11 iter 117: train loss 0.04337. lr 3.6949e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:37<00:00,  3.14it/s]
test loss: %f 0.03372695230479751
epoch 12 iter 117: train loss 0.06402. lr 3.6381e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:28<00:00,  4.13it/s]
test loss: %f 0.0236177328042686
step_train_loss: 0.05618125945329666 train_step: 1500, learning_rate: 0.00035944353638382785████████████▎                  | 84/118 [00:21<00:11,  3.08it/s]
epoch 13 iter 117: train loss 0.04255. lr 3.5771e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:35<00:00,  3.35it/s] 
test loss: %f 0.0318779285464968
epoch 14 iter 117: train loss 0.03576. lr 3.5119e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:38<00:00,  3.03it/s]
test loss: %f 0.016767480743250678
epoch 15 iter 117: train loss 0.01946. lr 3.4427e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:39<00:00,  2.98it/s]
test loss: %f 0.016557028849742243
epoch 16 iter 117: train loss 0.02432. lr 3.3697e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:36<00:00,  3.23it/s]
test loss: %f 0.016420267588858093
step_train_loss: 0.021356409415602684 train_step: 2000, learning_rate: 0.00032961106032120674█████████████████████████▊   | 112/118 [00:35<00:01,  5.17it/s]
epoch 17 iter 117: train loss 0.02619. lr 3.2930e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:37<00:00,  3.18it/s] 
test loss: %f 0.024427544458636215
epoch 18 iter 117: train loss 0.02204. lr 3.2130e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:41<00:00,  2.84it/s]
test loss: %f 0.017473825187023197
epoch 19 iter 117: train loss 0.01261. lr 3.1298e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:41<00:00,  2.81it/s]
test loss: %f 0.005108747487871109
epoch 20 iter 117: train loss 0.02998. lr 3.0436e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:42<00:00,  2.77it/s]
test loss: %f 0.005580304656177759
epoch 21 iter 117: train loss 0.01646. lr 2.9546e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:42<00:00,  2.77it/s]
test loss: %f 0.0071723222832328504
step_train_loss: 0.024443132802844048 train_step: 2500, learning_rate: 0.00029369277857326816                              | 22/118 [00:06<00:34,  2.79it/s]
epoch 22 iter 117: train loss 0.01488. lr 2.8632e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:40<00:00,  2.93it/s] 
test loss: %f 0.005704655993862876
epoch 23 iter 117: train loss 0.00696. lr 2.7694e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:36<00:00,  3.19it/s]
test loss: %f 0.011443533136376314
epoch 24 iter 117: train loss 0.00520. lr 2.6736e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:19<00:00,  5.96it/s]
test loss: %f 0.003991567022499761
epoch 25 iter 117: train loss 0.02054. lr 2.5761e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:35<00:00,  3.30it/s]
test loss: %f 0.018828447575547864
step_train_loss: 0.00471199955791235 train_step: 3000, learning_rate: 0.00025332841742237486                               | 50/118 [00:14<00:24,  2.82it/s]
epoch 26 iter 117: train loss 0.00617. lr 2.4770e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:37<00:00,  3.11it/s] 
test loss: %f 0.004703245175603245
epoch 27 iter 117: train loss 0.02349. lr 2.3767e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:40<00:00,  2.88it/s]
test loss: %f 0.005125444274329182
epoch 28 iter 117: train loss 0.01071. lr 2.2753e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:38<00:00,  3.04it/s]
test loss: %f 0.0034556927026382516
epoch 29 iter 117: train loss 0.01332. lr 2.1733e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:37<00:00,  3.19it/s]
test loss: %f 0.0045169348969856015
step_train_loss: 0.004856008570641279 train_step: 3500, learning_rate: 0.0002104478888917234████████▉                      | 78/118 [00:10<00:08,  4.67it/s]
epoch 30 iter 117: train loss 0.00641. lr 2.0708e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:25<00:00,  4.67it/s] 
test loss: %f 0.005818024929924702
epoch 31 iter 117: train loss 0.00164. lr 1.9681e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:29<00:00,  4.06it/s]
test loss: %f 0.002325727679168007
epoch 32 iter 117: train loss 0.00553. lr 1.8655e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:35<00:00,  3.28it/s]
test loss: %f 0.0027879435380912454
epoch 33 iter 117: train loss 0.00302. lr 1.7632e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:37<00:00,  3.18it/s]
test loss: %f 0.000782205036947354
step_train_loss: 0.0027759273070842028 train_step: 4000, learning_rate: 0.0001670744054881936██████████████████████▌      | 106/118 [00:18<00:02,  5.88it/s]
epoch 34 iter 117: train loss 0.00511. lr 1.6616e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:20<00:00,  5.88it/s] 
test loss: %f 0.00185320132108505
epoch 35 iter 117: train loss 0.00075. lr 1.5609e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:23<00:00,  4.95it/s]
test loss: %f 0.002124592694079703
epoch 36 iter 117: train loss 0.00138. lr 1.4613e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:28<00:00,  4.20it/s]
test loss: %f 0.0019915889715775847
epoch 37 iter 117: train loss 0.00184. lr 1.3631e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:29<00:00,  4.02it/s]
test loss: %f 0.00065242356543292
epoch 38 iter 117: train loss 0.00695. lr 1.2666e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:29<00:00,  4.05it/s]
test loss: %f 0.000733597220719925
step_train_loss: 0.004692401271313429 train_step: 4500, learning_rate: 0.0001252854199878168                               | 15/118 [00:01<00:09, 10.76it/s]
epoch 39 iter 117: train loss 0.00612. lr 1.1721e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:27<00:00,  4.32it/s] 
test loss: %f 0.0015264822234582556
epoch 40 iter 117: train loss 0.00063. lr 1.0797e-04: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:29<00:00,  4.03it/s]
test loss: %f 0.0006445915070279236
epoch 41 iter 117: train loss 0.00648. lr 9.8980e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:26<00:00,  4.42it/s]
test loss: %f 0.0009843476545938756
epoch 42 iter 117: train loss 0.00202. lr 9.0252e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:26<00:00,  4.43it/s]
test loss: %f 0.00037107222306076437
step_train_loss: 0.003964782692492008 train_step: 5000, learning_rate: 8.698867709645451e-05                               | 44/118 [00:11<00:13,  5.44it/s]
epoch 43 iter 117: train loss 0.00299. lr 8.1814e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:26<00:00,  4.49it/s] 
test loss: %f 0.0003727904789099869
epoch 44 iter 117: train loss 0.00243. lr 7.3688e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:27<00:00,  4.30it/s]
test loss: %f 0.0008335418931112924
epoch 45 iter 117: train loss 0.00093. lr 6.5895e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:29<00:00,  4.02it/s]
test loss: %f 0.0004022958055429626
epoch 46 iter 117: train loss 0.00031. lr 5.8455e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:30<00:00,  3.81it/s]
test loss: %f 0.00032586013795870325
step_train_loss: 0.0006137191667221487 train_step: 5500, learning_rate: 5.402406234055368e-05████▋                         | 72/118 [00:20<00:12,  3.57it/s]
epoch 47 iter 117: train loss 0.00125. lr 5.1389e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:33<00:00,  3.52it/s] 
test loss: %f 0.00021304900773040053
epoch 48 iter 117: train loss 0.00044. lr 4.4714e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:33<00:00,  3.55it/s]
test loss: %f 0.0002722274573118609
epoch 49 iter 117: train loss 0.00020. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:30<00:00,  3.84it/s]
test loss: %f 0.0009870466011696927
epoch 50 iter 117: train loss 0.00199. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:29<00:00,  4.02it/s]
test loss: %f 0.0003014971334778238
step_train_loss: 0.00014151225332170725 train_step: 6000, learning_rate: 4e-05██████████████████████████████████▏         | 100/118 [00:21<00:05,  3.55it/s]
epoch 51 iter 117: train loss 0.00081. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:26<00:00,  4.43it/s] 
test loss: %f 0.0002474925702569765
epoch 52 iter 117: train loss 0.00074. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:26<00:00,  4.42it/s]
test loss: %f 0.00022031491685733533
epoch 53 iter 117: train loss 0.00036. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:26<00:00,  4.40it/s]
test loss: %f 0.00038016479922069787
epoch 54 iter 117: train loss 0.00040. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:26<00:00,  4.42it/s]
test loss: %f 0.00022383122625667186
epoch 55 iter 117: train loss 0.00210. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:28<00:00,  4.12it/s]
test loss: %f 0.0005841520268664421
step_train_loss: 0.002322157146409154 train_step: 6500, learning_rate: 4e-05                                               | 10/118 [00:02<00:30,  3.55it/s]
epoch 56 iter 117: train loss 0.00029. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:30<00:00,  3.83it/s] 
test loss: %f 6.198502420115151e-05
epoch 57 iter 117: train loss 0.00015. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:33<00:00,  3.57it/s]
test loss: %f 0.0008419974096796068
epoch 58 iter 117: train loss 0.00172. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:33<00:00,  3.52it/s]
test loss: %f 0.00011788887591787247
epoch 59 iter 117: train loss 0.00081. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:31<00:00,  3.79it/s]
test loss: %f 0.00029612903102003784
step_train_loss: 0.0009409009362570941 train_step: 7000, learning_rate: 4e-05█▉                                            | 38/118 [00:06<00:13,  6.06it/s]
epoch 60 iter 117: train loss 0.00061. lr 4.0000e-05: 100%|███████████████████████████████████████████████████████████████| 118/118 [00:29<00:00,  3.96it/s] 
test loss: %f 0.0003716399638246263
epoch_valid_loss: 0.0003716399638246263, epoch_train_loss: 0.001117120959198643, epoch: 60
Saving at epoch 60: ./cond_gpt/weights/None_simplesplit_10layer_16head_256embd_128bs.pt

(csce) C:\Users\hussein\Desktop\DL-GPT-for-scan>